<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Jonathan Landy" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Methods, Theory, " />

<meta property="og:title" content="Bayesian Statistics: MCMC "/>
<meta property="og:url" content="https://efavdb.com/metropolis" />
<meta property="og:description" content="We review the Metropolis algorithm — a simple Markov Chain Monte Carlo (MCMC) sampling method — and its application to estimating posteriors in Bayesian statistics. A simple python example is provided. Introduction One of the central aims of statistics is to identify good methods for fitting models to data. One way to …" />
<meta property="og:site_name" content="EFAVDB" />
<meta property="og:article:author" content="Jonathan Landy" />
<meta property="og:article:published_time" content="2016-08-07T18:37:00-07:00" />
<meta name="twitter:title" content="Bayesian Statistics: MCMC ">
<meta name="twitter:description" content="We review the Metropolis algorithm — a simple Markov Chain Monte Carlo (MCMC) sampling method — and its application to estimating posteriors in Bayesian statistics. A simple python example is provided. Introduction One of the central aims of statistics is to identify good methods for fitting models to data. One way to …">

        <title>Bayesian Statistics: MCMC  · EFAVDB
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Fira+Sans:300,400,700" rel="stylesheet" type='text/css' />
        <link href="https://fonts.googleapis.com/css?family=Cardo:400,700" rel="stylesheet" type='text/css' />        
        <link rel="stylesheet" type="text/css" href="https://efavdb.com/theme/css/elegant.prod.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://efavdb.com/theme/css/custom.css" media="screen">

        <link href="https://efavdb.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="EFAVDB - Full Atom Feed" />
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-57405119-1', 'auto');
    ga('send', 'pageview');
</script>


    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://efavdb.com/"><span class=site-name>EFAVDB</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://efavdb.com
                                    >Home</a>
                                </li>
                                <li ><a href="https://efavdb.com/pages/authors.html">Authors</a></li>
                                <li ><a href="https://efavdb.com/categories.html">Categories</a></li>
                                <li ><a href="https://efavdb.com/tags.html">Tags</a></li>
                                <li ><a href="https://efavdb.com/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://efavdb.com/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span8 offset2">
        <h1>
            <a href="https://efavdb.com/metropolis">
                Bayesian Statistics: <span class="caps">MCMC</span>
            </a>
        </h1>
    </header>
    <div class="span2"></div>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>We review the Metropolis algorithm &#8212; a simple Markov Chain Monte Carlo (<span class="caps">MCMC</span>) sampling method &#8212; and its application to estimating posteriors in Bayesian statistics. A simple python example is&nbsp;provided.</p>
<h2>Introduction</h2>
<p>One of the central aims of statistics is to identify good methods for fitting models to data. One way to do this is through the use of Bayes&#8217; rule: If <span class="math">\(\textbf{x}\)</span> is a vector of <span class="math">\(k\)</span> samples from a distribution and <span class="math">\(\textbf{z}\)</span> is a vector of model parameters, Bayes&#8217; rule&nbsp;gives
</p>
<div class="math">\begin{align} \tag{1} \label{Bayes}
p(\textbf{z} \vert \textbf{x}) = \frac{p(\textbf{x} \vert \textbf{z}) p(\textbf{z})}{p(\textbf{x})}.
\end{align}</div>
<p>
Here, the probability at left, <span class="math">\(p(\textbf{z} \vert \textbf{x})\)</span> &#8212; the &#8220;posterior&#8221; &#8212; is a function that tells us how likely it is that the underlying true parameter values are <span class="math">\(\textbf{z}\)</span>, given the information provided by our observations <span class="math">\(\textbf{x}\)</span>. Notice that if we could solve for this function, we would be able to identify which parameter values are most likely &#8212; those that are good candidates for a fit. We could also use the posterior&#8217;s variance to quantify how uncertain we are about the true, underlying parameter&nbsp;values.</p>
<p>Bayes&#8217; rule gives us a method for evaluating the posterior &#8212; now our goal: We need only evaluate the right side of (\ref{Bayes}). The quantities shown there&nbsp;are</p>
<p><span class="math">\(p(\textbf{x} \vert \textbf{z})\)</span> &#8212; This is the probability of seeing <span class="math">\(\textbf{x}\)</span> at fixed parameter values <span class="math">\(\textbf{z}\)</span>. Note that if the model is specified, we can often immediately write this part down. For example, if we have a Normal distribution model, specifying <span class="math">\(\textbf{z}\)</span> means that we have specified the Normal&#8217;s mean and variance. Given these, we can say how likely it is to observe any <span class="math">\(\textbf{x}\)</span>.</p>
<p><span class="math">\(p(\textbf{z})\)</span> &#8212; the &#8220;prior&#8221;. This is something we insert by hand before taking any data. We choose its form so that it covers the values we expect are reasonable for the parameters in&nbsp;question.</p>
<p><span class="math">\(p(\textbf{x})\)</span> &#8212; the denominator. Notice that this doesn&#8217;t depend on <span class="math">\(\textbf{z}\)</span>, and so represents a normalization constant for the&nbsp;posterior.</p>
<p>It turns out that the last term above can sometimes be difficult to evaluate analytically, and so we must often resort to numerical methods for estimating the posterior. Monte Carlo sampling is one of the most common approaches taken for doing this. The idea behind Monte Carlo is to take many samples <span class="math">\(\{\textbf{z}_i\}\)</span> from the posterior (\ref{Bayes}). Once these are obtained, we can approximate population averages by averages over the samples. For example, the true posterior average <span class="math">\(\langle\textbf{z} \rangle \equiv \int \textbf{z} p(\textbf{z} \vert \textbf{x}) d \textbf{z}\)</span> can be approximated by <span class="math">\(\overline{\textbf{z}} \equiv \frac{1}{N}\sum_i \textbf{z}_i\)</span>, the sample average. By the law of large numbers, the sample averages are guaranteed to approach the distribution averages as <span class="math">\(N \to \infty\)</span>. This means that Monte Carlo can always be used to obtain very accurate parameter estimates, provided we take <span class="math">\(N\)</span> sufficiently large &#8212; and that we can find a convenient way to sample from the posterior. In this post, we review one simple variant of Monte Carlo that allows for posterior sampling: the Metropolis&nbsp;algorithm.</p>
<h2>Metropolis&nbsp;Algorithm</h2>
<h3>Iterative&nbsp;Procedure</h3>
<p>Metropolis is an iterative, try-accept algorithm. We initialize the algorithm by selecting a parameter vector <span class="math">\(\textbf{z}\)</span> at random. Following this, we repeatedly carry out the following two steps to obtain additional posterior&nbsp;samples:</p>
<ol>
<li>Identify a next candidate sample <span class="math">\(\textbf{z}_j\)</span> via some random process. This candidate selection step can be informed by the current sample&#8217;s position, <span class="math">\(\textbf{z}_i\)</span>. For example, one could require that the next candidate be selected from those parameter vectors a given step-size distance from the current sample, <span class="math">\(\textbf{z}_j \in \{\textbf{z}_k: \vert \textbf{z}_i - \textbf{z}_k \vert = \delta \}\)</span>. However, while the candidate selected can depend on the current sample, it must not depend on any prior history of the sampling process. Whatever the process chosen (there&#8217;s some flexibility here), we write <span class="math">\(t_{i,j}\)</span> for the rate of selecting <span class="math">\(\textbf{z}_j\)</span> as the next candidate given the current sample is <span class="math">\(\textbf{z}_i\)</span>.</li>
<li>Once a candidate is identified, we either accept or reject it via a second random process. If it is accepted, we mark it down as the next sample, then go back to step one, using the current sample to inform the next candidate selection. Otherwise, we mark the current sample down again, taking it as a repeat sample, and then use it to return to candidate search step, as above. Here, we write <span class="math">\(A_{i,j}\)</span> for the rate of accepting <span class="math">\(\textbf{z}_j\)</span>, given that it was selected as the next candidate, starting from <span class="math">\(\textbf{z}_i\)</span>.</li>
</ol>
<h3>Selecting the trial and acceptance&nbsp;rates</h3>
<p><a href="https://efavdb.com/wp-content/uploads/2016/08/Untitled-1.jpg"><img alt="Untitled-1" src="https://efavdb.com/wp-content/uploads/2016/08/Untitled-1.jpg"></a></p>
<p>In order to ensure that our above process selects samples according to the distribution (\ref{Bayes}), we need to appropriately set the <span class="math">\(\{t_{i,j}\}\)</span> and <span class="math">\(\{A_{i,j}\}\)</span> values. To do that, note that at equilibrium one must see the same number of hops from <span class="math">\(\textbf{z}_i\)</span> to <span class="math">\(\textbf{z}_j\)</span> as hops from <span class="math">\(\textbf{z}_j\)</span> from <span class="math">\(\textbf{z}_i\)</span> (if this did not hold, one would see a net shifting of weight from one to the other over time, contradicting the assumption of equilibrium). If <span class="math">\(\rho_i\)</span> is the fraction of samples the process takes from state <span class="math">\(i\)</span>, this condition can be written&nbsp;as
</p>
<div class="math">\begin{align} \label{inter}
\rho_i t_{i,j} A_{i,j} = \rho_j t_{j,i} A_{j,i} \tag{3}
\end{align}</div>
<p>
To select a process that returns the desired sampling weight, we solve for <span class="math">\(\rho_i\)</span> over <span class="math">\(\rho_j\)</span> in (\ref{inter}) and then equate this to the ratio required by (\ref{Bayes}). This&nbsp;gives
</p>
<div class="math">\begin{align} \tag{4} \label{cond}
\frac{\rho_i}{\rho_j} = \frac{t_{j,i} A_{j,i}}{t_{i,j} A_{i,j}}
\equiv \frac{p(\textbf{x} \vert \textbf{z}_i)p(\textbf{z}_i)}{p(\textbf{x} \vert \textbf{z}_j)p(\textbf{z}_j)}.
\end{align}</div>
<p>
Now, the single constraint above is not sufficient to pin down all of our degrees of freedom. In the Metropolis case, we choose the following working balance: The trial rates between states are set equal, <span class="math">\(t_{i,j} = t_{j,i}\)</span> (but remain unspecified &#8212; left to the discretion of the coder on a case-by-case basis), and we&nbsp;set
</p>
<div class="math">$$ \tag{5}
A_{i,j} = \begin{cases}
1, &amp; \text{if } p(\textbf{z}_j \vert \textbf{x}) &gt; p(\textbf{z}_i \vert \textbf{x}) \\
\frac{p(\textbf{x} \vert \textbf{z}_j)p(\textbf{z}_j)}{p(\textbf{x} \vert \textbf{z}_i)p(\textbf{z}_i)} \equiv \frac{p(\textbf{z}_j \vert \textbf{x})}{p(\textbf{z}_i \vert \textbf{x})}, &amp; \text{else}.
\end{cases}
$$</div>
<p>
This last equation says that we choose to always accept a candidate sample if it is more likely than the current one. However, if the candidate is less likely, we only accept a fraction of the time &#8212; with rate equal to the relative probability ratio of the two states. For example, if the candidate is only <span class="math">\(80%\)</span> as likely as the current sample, we accept it <span class="math">\(80%\)</span> of the time. That&#8217;s it for Metropolis &#8212; a simple <span class="caps">MCMC</span> algorithm, guaranteed to satisfy (\ref{cond}), and to therefore equilibrate to (\ref{Bayes})! An example&nbsp;follows.</p>
<h3>Coding&nbsp;example</h3>
<p>The following python snippet illustrates the Metropolis algorithm in action. Here, we take 15 samples from a Normal distribution of variance one and true mean also equal to one. We pretend not to know the mean (but assume we do know the variance), assume a uniform prior for the mean, and then run the algorithm to obtain two hundred thousand samples from the mean&#8217;s posterior. <a href="https://efavdb.com/wp-content/uploads/2016/08/result-1.png"><img alt="result" src="https://efavdb.com/wp-content/uploads/2016/08/result-1.png"></a> The histogram at right summarizes the results, obtained by dropping the first 1% of the samples (to protect against bias towards the initialization value). Averaging over the samples returns a mean estimate of <span class="math">\(\mu \approx 1.4 \pm 0.5\)</span> (95% confidence interval), consistent with the true value of <span class="math">\(1\)</span>.</p>
<div class="highlight"><pre><span></span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Take some samples</span>
<span class="n">true_mean</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">true_mean</span><span class="p">,</span> <span class="kp">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">total_samples</span> <span class="o">=</span> <span class="mi">200000</span>

<span class="c1"># Function used to decide move acceptance</span>
<span class="k">def</span> <span class="nf">posterior_numerator</span><span class="p">(</span><span class="n">mu</span><span class="p">):</span>
    <span class="kp">prod</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>
        <span class="kp">prod</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="kp">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="kp">prod</span>

<span class="c1"># Initialize MCMC, then iterate</span>
<span class="n">z1</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">posterior_samples</span> <span class="o">=</span> <span class="p">[</span><span class="n">z1</span><span class="p">]</span>

<span class="k">while</span> <span class="nb">len</span><span class="p">(</span><span class="n">posterior_samples</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">total_samples</span><span class="p">:</span>
    <span class="n">z_current</span> <span class="o">=</span> <span class="n">posterior_samples</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">z_candidate</span> <span class="o">=</span> <span class="n">z_current</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">-</span> <span class="mf">0.5</span>
    <span class="n">rel_prob</span> <span class="o">=</span> <span class="n">posterior_numerator</span><span class="p">(</span>
        <span class="n">z_candidate</span><span class="p">)</span> <span class="o">/</span> <span class="n">posterior_numerator</span><span class="p">(</span><span class="n">z_current</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">rel_prob</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">posterior_samples</span><span class="o">.</span><span class="kp">append</span><span class="p">(</span><span class="n">z_candidate</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">trial_toss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">trial_toss</span> <span class="o">&lt;</span> <span class="n">rel_prob</span><span class="p">:</span>
            <span class="n">posterior_samples</span><span class="o">.</span><span class="kp">append</span><span class="p">(</span><span class="n">z_candidate</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">posterior_samples</span><span class="o">.</span><span class="kp">append</span><span class="p">(</span><span class="n">z_current</span><span class="p">)</span>

<span class="c1"># Drop some initial samples and thin</span>
<span class="n">thinned_samples</span> <span class="o">=</span> <span class="n">posterior_samples</span><span class="p">[</span><span class="mi">2000</span><span class="p">:]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">thinned_samples</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Histogram of MCMC samples&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<h3>Summary</h3>
<p>To summarize, we have reviewed the application of <span class="caps">MCMC</span> to Bayesian statistics. <span class="caps">MCMC</span> is a general tool for obtaining samples from a probability distribution. It can be applied whenever one can conveniently specify the relative probability of two states &#8212; and so is particularly apt for situations where only the normalization constant of a distribution is difficult to evaluate, precisely the problem with the posterior (\ref{Bayes}). The method entails carrying out an iterative try-accept algorithm, where the rates of trial and acceptance can be adjusted, but must be balanced so that the equilibrium distribution that results approaches the desired form. The key equation enabling us to strike this balance is (\ref{inter}) &#8212; the zero flux condition (aka the <em>detailed balance</em> condition to physicists) that holds between states at&nbsp;equilibrium.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>


             
 
                <p id="post-share-links">
    Like this post?  Share on:
    <a href="https://twitter.com/intent/tweet?text=Bayesian%20Statistics%3A%20MCMC&url=https%3A//efavdb.com/metropolis" target="_blank" rel="nofollow noopener noreferrer" title="Share on Twitter">Twitter</a>
    ❄
    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//efavdb.com/metropolis" target="_blank" rel="nofollow noopener noreferrer" title="Share on Facebook">Facebook</a>
    ❄
    <a href="mailto:?subject=Bayesian%20Statistics%3A%20MCMC&amp;body=https%3A//efavdb.com/metropolis" target="_blank" rel="nofollow noopener noreferrer" title="Share via Email">Email</a>
    </p>

                <hr />
    <div class="author_blurb">
        <a href="" target="_blank" rel="nofollow noopener noreferrer">
            <img src=/wp-content/uploads/2014/12/JonathanLinkedIn.jpg alt="Jonathan Landy Avatar" title="Jonathan Landy">
            <span class="author_name">Jonathan Landy</span>
        </a>
        Jonathan grew up in the midwest and then went to school at Caltech and UCLA. Following this, he did two postdocs, one at UCSB and one at UC Berkeley.  His academic research focused primarily on applications of statistical mechanics, but his professional passion has always been in the mastering, development, and practical application of slick math methods/tools. He worked as a data-scientist at Square for four years and is now working on a quantitative investing startup.
    </div>

            






<section>
    <h6 style="display:none;">Comments</h6>
    <p id="comment-message"> </p>

    <div class="accordion" id="accordion2">
        <div class="accordion-group">
            <div class="accordion-heading">
                <a class="accordion-toggle disqus-comment-count comment-count"
                   data-toggle="collapse"
                   data-parent="#accordion2"
                   data-disqus-identifier="https://efavdb.com/metropolis"
                   href="https://efavdb.com/metropolis#comment_thread"
                   id="comment-accordion-toggle">
                    Comments
                </a>
            </div>
            <div id="comment_thread" class="accordion-body collapse">
                <div class="accordion-inner">
                    <div class="comments">
                        <div id="disqus_thread"></div>
                        <script>
    var disqus_shortname = 'efavdb2';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());

    var disqus_identifier = 'https://efavdb.com/metropolis';
    var disqus_url = 'https://efavdb.com/metropolis';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>

<noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

            <hr/>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="previous-article">« <a href="https://efavdb.com/interpret-linear-regression" title="Previous: Interpreting the results of linear regression">Interpreting the results of linear regression</a></li>
                <li class="next-article"><a href="https://efavdb.com/model-selection" title="Next: Hyperparameter sample-size dependence">Hyperparameter sample-size dependence</a> »</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2016-08-07T18:37:00-07:00">Aug 7, 2016</time>
            <h4>Category</h4>
            <a class="category-link" href="https://efavdb.com/categories.html#methods-theory-ref">Methods, Theory</a>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://twitter.com/efavdb" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="Twitter" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1da1f3"/><path fill="#fff" d="M437 152a72 72 0 0 1-40 12 72 72 0 0 0 32-40 72 72 0 0 1-45 17 72 72 0 0 0-122 65 200 200 0 0 1-145-74 72 72 0 0 0 22 94 72 72 0 0 1-32-7 72 72 0 0 0 56 69 72 72 0 0 1-32 1 72 72 0 0 0 67 50 200 200 0 0 1-105 29 200 200 0 0 0 309-179 200 200 0 0 0 35-37"/></svg>
    </a>
    <a href="https://github.com/efavdb" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
    <a href="https://www.youtube.com/channel/UClfvjoSiu0VvWOh5OpnuusA" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="YouTube" role="img" viewBox="0 0 512 512" fill="#ed1d24"><rect width="512" height="512" rx="15%"/><path d="m427 169c-4-15-17-27-32-31-34-9-239-10-278 0-15 4-28 16-32 31-9 38-10 135 0 174 4 15 17 27 32 31 36 10 241 10 278 0 15-4 28-16 32-31 9-36 9-137 0-174" fill="#fff"/><path d="m220 203v106l93-53"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
                        <button onclick="topFunction()" id="myBtn" title="Go to top">&#x25B2;</button>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>

    <div>
        <span class="site-name">EFAVDB</span> - Everybody's Favorite Data Blog
    </div>



    <!-- <div id="fpowered"> -->
    <!--     Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a> -->
    <!--     Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a> -->
    <!--      -->
    <!-- </div> -->
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>
        <script>
            //** Scroll to top button **
            //Get the button:
            mybutton = document.getElementById("myBtn");

            // When the user scrolls down 30px from the top of the document, show the button
            window.onscroll = function() {scrollFunction()};

            function scrollFunction() {
              if (document.body.scrollTop > 30 || document.documentElement.scrollTop > 30) {
                mybutton.style.display = "block";
              } else {
                mybutton.style.display = "none";
              }
            }

            // When the user clicks on the button, scroll to the top of the document
            function topFunction() {
              document.body.scrollTop = 0; // For Safari
              document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>