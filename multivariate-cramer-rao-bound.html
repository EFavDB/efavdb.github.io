<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Jonathan Landy" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Statistics, " />

<meta property="og:title" content="Multivariate Cramer-Rao inequality "/>
<meta property="og:url" content="./multivariate-cramer-rao-bound.html" />
<meta property="og:description" content="The Cramer-Rao inequality addresses the question of how accurately one can estimate a set of parameters \(\vec{\theta} = \{\theta_1, \theta_2, \ldots, \theta_m \}\) characterizing a probability distribution \(P(x) \equiv P(x; \vec{\theta})\), given only some samples \(\{x_1, \ldots, x_n\}\) taken from \(P\). Specifically, the inequality provides a rigorous lower …" />
<meta property="og:site_name" content="EFAVDB" />
<meta property="og:article:author" content="Jonathan Landy" />
<meta property="og:article:published_time" content="2015-06-20T09:00:00-07:00" />
<meta name="twitter:title" content="Multivariate Cramer-Rao inequality ">
<meta name="twitter:description" content="The Cramer-Rao inequality addresses the question of how accurately one can estimate a set of parameters \(\vec{\theta} = \{\theta_1, \theta_2, \ldots, \theta_m \}\) characterizing a probability distribution \(P(x) \equiv P(x; \vec{\theta})\), given only some samples \(\{x_1, \ldots, x_n\}\) taken from \(P\). Specifically, the inequality provides a rigorous lower …">

        <title>Multivariate Cramer-Rao inequality  · EFAVDB
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Fira+Sans:300,400,700" rel="stylesheet" type='text/css' />
        <link href="https://fonts.googleapis.com/css?family=Cardo" rel="stylesheet" type='text/css' />        
        <link rel="stylesheet" type="text/css" href="./theme/css/elegant.prod.css" media="screen">
        <link rel="stylesheet" type="text/css" href="./theme/css/custom.css" media="screen">



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="./"><span class=site-name>EFAVDB</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       .
                                    >Home</a>
                                </li>
                                <li ><a href="./pages/authors.html">Authors</a></li>
                                <li ><a href="./categories.html">Categories</a></li>
                                <li ><a href="./tags.html">Tags</a></li>
                                <li ><a href="./archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="./search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span8 offset2">
        <h1>
            <a href="./multivariate-cramer-rao-bound.html">
                Multivariate Cramer-Rao&nbsp;inequality
            </a>
        </h1>
    </header>
    <div class="span2"></div>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>The Cramer-Rao inequality addresses the question of how accurately one can estimate a set of parameters <span class="math">\(\vec{\theta} = \{\theta_1, \theta_2, \ldots, \theta_m \}\)</span> characterizing a probability distribution <span class="math">\(P(x) \equiv P(x; \vec{\theta})\)</span>, given only some samples <span class="math">\(\{x_1, \ldots, x_n\}\)</span> taken from <span class="math">\(P\)</span>. Specifically, the inequality provides a rigorous lower bound on the covariance matrix of any unbiased set of estimators to these <span class="math">\(\{\theta_i\}\)</span> values. In this post, we review the general, multivariate form of the inequality, including its significance and&nbsp;proof.  </p>
<h3>Introduction and theorem&nbsp;statement</h3>
<p>The analysis of data very frequently requires one to attempt to characterize a probability distribution. For instance, given some random, stationary process that generates samples <span class="math">\(\{x_i\}\)</span>, one might wish to estimate the mean <span class="math">\(\mu\)</span> of the probability distribution <span class="math">\(P\)</span> characterizing this process. To do this, one could construct an estimator function <span class="math">\(\hat{\mu}(\{x_i\})\)</span> &#8212; a function of some samples taken from <span class="math">\(P\)</span> &#8212; that is intended to provide an approximation to <span class="math">\(\mu\)</span>. Given <span class="math">\(n\)</span> samples, a natural choice is provided by<br>
</p>
<div class="math">$$  
\hat{\mu}(\{x_i\}) = \frac{1}{n}\sum_{i = 1}^n x_i, \tag{1}  
$$</div>
<p><br>
the mean of the samples. This particular choice of estimator will always be unbiased given a stationary <span class="math">\(P\)</span> &#8212; meaning that it will return the correct result, on average. However, each particular sample set realization will return a slightly different mean estimate. This means that <span class="math">\(\hat{\mu}\)</span> is itself a random variable having its own distribution and&nbsp;width.</p>
<p>More generally, one might be interested in a distribution characterized by a set of <span class="math">\(m\)</span> parameters <span class="math">\(\{\theta_i\}\)</span>. Consistently good estimates to these values require estimators with distributions that are tightly centered around the true <span class="math">\(\{\theta_i\}\)</span> values. The Cramer-Rao inequality tells us that there is a fundamental limit to how tightly centered such estimators can be, given only <span class="math">\(n\)</span> samples. We state the result&nbsp;below.</p>
<p><strong>Theorem:</strong> <em>The multivariate Cramer-Rao inequality</em>.</p>
<p>Let <span class="math">\(P\)</span> be a distribution characterized by a set of <span class="math">\(m\)</span> parameters <span class="math">\(\{\theta_i\}\)</span>, and let <span class="math">\(\{\hat{\theta_i}\equiv \hat{\theta_i}(\{x_i\})\}\)</span> be an unbiased set of estimator functions for these parameters. Then, the covariance matrix (see definition below) for the <span class="math">\(\hat{\{\theta_i\}}\)</span>&nbsp;satisfies,</p>
<div class="math">$$ cov(\hat{\theta}, \hat{\theta}) \geq \frac{1}{n} \times \frac{1}{ cov(\nabla_{\vec{\theta}} \log P(x),\nabla_{\vec{\theta}} \log P(x) )}. \tag{2} \label{CR} $$</div>
<p><br>
Here, the inequality holds in the sense that left side of the above equation, minus the right, is positive semi-definite. We discuss the meaning and significance of this equation in the next&nbsp;section.</p>
<h3>Interpretation of the&nbsp;result</h3>
<p>To understand (\ref{<span class="caps">CR</span>}), we must first review a couple of definitions. These&nbsp;follow.</p>
<p><strong>Definition 1</strong>. Let <span class="math">\(\vec{u}\)</span> and <span class="math">\(\vec{v}\)</span> be two jointly-distributed vectors of stationary random variables. The covariance matrix of <span class="math">\(\vec{u}\)</span> and <span class="math">\(\vec{v}\)</span> is defined by<br>
</p>
<div class="math">$$  
cov(\vec{u}, \vec{v})_{ij} = \overline{(u_{i}- \overline{u_i})(v_{j}- \overline{v_j})} \equiv \overline{\delta u_{i} \delta v_{j}}\tag{3} \label{cov},  
$$</div>
<p><br>
where we use overlines for averages. In words, (\ref{cov}) states that <span class="math">\(cov(\vec{u}, \vec{v})_{ij}\)</span> is the correlation function of the fluctuations of <span class="math">\(u_i\)</span> and <span class="math">\(v_j\)</span>.</p>
<p><strong>Definition 2</strong>. A real, square matrix <span class="math">\(M\)</span> is said to be positive semi-definite if<br>
</p>
<div class="math">$$  
\vec{a}^T\cdot M \cdot \vec{a} \geq 0 \tag{4} \label{pd}  
$$</div>
<p><br>
for all real vectors <span class="math">\(\vec{a}\)</span>. It is positive definite if the &#8220;<span class="math">\(\geq\)</span>&#8221; above can be replaced by a &#8220;<span class="math">\(&gt;\)</span><span class="dquo">&#8220;</span>.</p>
<p>The interesting consequences of (\ref{<span class="caps">CR</span>}) follow from the following&nbsp;observation:</p>
<p><strong>Observation</strong>. For any constant vectors <span class="math">\(\vec{a}\)</span> and <span class="math">\(\vec{b}\)</span>, we have<br>
</p>
<div class="math">$$  
cov(\vec{a}^T\cdot\vec{u}, \vec{b}^T \cdot \vec{v}) = \vec{a}^T \cdot cov(\vec{u}, \vec{v}) \cdot \vec{b}. \tag{5} \label{fact}  
$$</div>
<p><br>
This follows from the definition&nbsp;(\ref{cov}).</p>
<p>Taking <span class="math">\(\vec{a}\)</span> and <span class="math">\(\vec{b}\)</span> to both be along <span class="math">\(\hat{i}\)</span> in (\ref{fact}), and combining with (\ref{pd}), we see that (\ref{<span class="caps">CR</span>}) implies that<br>
</p>
<div class="math">$$  
\sigma^2(\hat{\theta}_i^2) \geq \frac{1}{n} \times \left (\frac{1}{ cov(\nabla_{\vec{\theta}} \log P(x),\nabla_{\vec{\theta}} \log P(x) )} \right)_{ii},\tag{6}\label{CRsimple}  
$$</div>
<p><br>
where we use <span class="math">\(\sigma^2(x)\)</span> to represent the variance of <span class="math">\(x\)</span>. The left side of (\ref{CRsimple}) is the variance of the estimator function <span class="math">\(\hat{\theta}_i\)</span>, whereas the right side is a function of <span class="math">\(P\)</span> only. This tells us that there is fundamental &#8212; distribution-dependent &#8212; lower limit on the uncertainty one can achieve when attempting to estimate <em>any parameter characterizing a distribution</em>. In particular, (\ref{CRsimple}) states that the best variance one can achieve scales like <span class="math">\(O(1/n)\)</span>, where <span class="math">\(n\)</span> is the number of samples available<span class="math">\(^1\)</span> &#8212; very&nbsp;interesting!</p>
<p>Why is there a relationship between the left and right matrices in (\ref{<span class="caps">CR</span>})? Basically, the right side relates to the inverse rate at which the probability of a given <span class="math">\(x\)</span> changes with <span class="math">\(\theta\)</span>: If <span class="math">\(P(x \vert \theta)\)</span> is highly peaked, the gradient of <span class="math">\(P(x \vert \theta)\)</span> will take on large values. In this case, a typical observation <span class="math">\(x\)</span> will provide significant information relating to the true <span class="math">\(\theta\)</span> value, allowing for unbiased <span class="math">\(\hat{\theta}\)</span> estimates that have low variance. In the opposite limit, where typical observations are not very <span class="math">\(\theta\)</span>-informative, unbiased <span class="math">\(\hat{\theta}\)</span> estimates must have large variance<span class="math">\(^2\)</span>.</p>
<p>We now turn to the proof of (\ref{<span class="caps">CR</span>}).</p>
<h3>Theorem&nbsp;proof</h3>
<p>Our discussion here expounds on that in the <a href="http://sfb649.wiwi.hu-berlin.de/fedc_homepage/xplore/tutorials/mvahtmlframe74.html">online text</a> of Cízek, Härdle, and Weron. We start by deriving a few simple lemmas. We state and derive these sequentially&nbsp;below.</p>
<p><strong>Lemma 1</strong> Let <span class="math">\(T_j(\{x_i\}) \equiv \partial_{\theta_j} \log P(\{x_i\}; \vec{\theta})\)</span> be a function of a set of independent sample values <span class="math">\(\{x_i\}\)</span>. Then, the average of <span class="math">\(T_j(\{x_i\})\)</span> is&nbsp;zero.</p>
<p><em>Proof:</em> We obtain the average of <span class="math">\(T_j(\{x_i\})\)</span> through integration over the <span class="math">\(\{x_i\}\)</span>, weighted by <span class="math">\(P\)</span>,<br>
</p>
<div class="math">$$  
\int P(\{x_i\};\vec{\theta}) \partial_{\theta_j} \log P(\{x_i\}; \vec{\theta}) d\vec{x} = \int P \frac{\partial_{\theta_j} P}{P} d\vec{x} = \partial_{\theta_j} \int P d\vec{x} = \partial_{\theta_j} 1 = 0. \tag{7}  
$$</div>
<p><strong>Lemma 2</strong>. The covariance matrix of an unbiased <span class="math">\(\hat{\theta}\)</span> and <span class="math">\(\vec{T}\)</span> is the identity&nbsp;matrix.</p>
<p><em>Proof:</em> Using (\ref{cov}), the assumed fact that <span class="math">\(\hat{\theta}\)</span> is unbiased, and Lemma 1, we have<br>
</p>
<div class="math">$$\begin{align}  
cov \left (\hat{\theta}(\{x_i\}), \vec{T}(\{x_i\}) \right)_{jk} &amp;= \int P(\{x_i\}) (\hat{\theta}_j - \theta_j ) \partial_{\theta_k} \log P(\{x_i\}) d\vec{x}\\ &amp; = \int (\hat{\theta}_j - \theta_j ) \partial_{\theta_k} P d\vec{x} \\  
&amp;= -\int P \partial_{\theta_k} (\hat{\theta}_j - \theta_j ) d \vec{x} \tag{8}  
\end{align}  
$$</div>
<p><br>
Here, we have integrated by parts in the last line. Now, <span class="math">\(\partial_{\theta_k} \theta_j = \delta_{jk}\)</span>. Further, <span class="math">\(\partial_{\theta_k} \hat{\theta}_j = 0\)</span>, since <span class="math">\(\hat{\theta}\)</span> is a function of the samples <span class="math">\(\{x_i\}\)</span> only. Plugging these results into the last line, we obtain<br>
</p>
<div class="math">$$  
cov \left (\hat{\theta}, \vec{T} \right)_{jk} = \delta_{jk} \int P d\vec{x} = \delta_{jk}. \tag{9}  
$$</div>
<p><strong>Lemma 3</strong>. The covariance matrix of <span class="math">\(\vec{T}\)</span> is <span class="math">\(n\)</span> times the covariance matrix of <span class="math">\(\nabla_{\vec{\theta}} \log P(x_1 ; \vec{\theta})\)</span> &#8212; a single-sample version of <span class="math">\(\vec{T}\)</span>.</p>
<p><em>Proof:</em> From the definition of <span class="math">\(\vec{T}\)</span>, we have<br>
</p>
<div class="math">$$  
T_j = \partial_{\theta_j} \log P(\{x_i\}, \vec{\theta}) = \sum_{i=1}^n \partial_{\theta_j} \log P(x_i, \vec{\theta}), \tag{10}  
$$</div>
<p><br>
where the last line follows from the fact that the <span class="math">\(\{x_i\}\)</span> are independent, so that <span class="math">\(P(\{x_i\}, \vec{\theta}) = \prod P(x_i; \vec{\theta})\)</span>. The sum on the right side of the above equation is a sum of <span class="math">\(n\)</span> independent, identically-distributed random variables. If follows that their covariance matrix is <span class="math">\(n\)</span> times that for any&nbsp;individual.</p>
<p><strong>Lemma 4</strong>. Let <span class="math">\(x\)</span> and <span class="math">\(y\)</span> be two scalar stationary random variables. Then, their correlation coefficient is defined to be <span class="math">\(\rho \equiv \frac{cov(x,y)}{\sigma(x) \sigma(y)}\)</span>. This satisfies<br>
</p>
<div class="math">$$  
-1 \leq \rho \leq 1 \label{CC} \tag{11}  
$$</div>
<p><em>Proof:</em> Consider the variance of <span class="math">\(\frac{x}{\sigma(x)}+\frac{y}{\sigma(y)}\)</span>. This is<br>
</p>
<div class="math">$$  
\begin{align}  
var \left( \frac{x}{\sigma(x)}+\frac{y}{\sigma(y)} \right) &amp;= \frac{\sigma^2(x)}{\sigma^2(x)} + 2\frac{ cov(x,y)}{\sigma(x) \sigma(y)} + \frac{\sigma^2(y)}{\sigma^2(y)} \\  
&amp;= 2 + 2 \frac{ cov(x,y)}{\sigma(x) \sigma(y)} \geq 0. \tag{12}  
\end{align}  
$$</div>
<p><br>
This gives the left side of (\ref{<span class="caps">CC</span>}). Similarly, considering the variance of <span class="math">\(\frac{x}{\sigma(x)}-\frac{y}{\sigma(y)}\)</span> gives the right&nbsp;side.</p>
<p>We&#8217;re now ready to prove the Cramer-Rao&nbsp;result.</p>
<p><strong>Proof of Cramer-Rao inequality</strong>. Consider the correlation coefficient of the two scalars <span class="math">\(\vec{a} \cdot \hat{\theta}\)</span> and <span class="math">\( \vec{b} \cdot \vec{T}\)</span>, with <span class="math">\(\vec{a}\)</span> and <span class="math">\(\vec{b}\)</span> some constant vectors. Using (\ref{fact}) and Lemma 2, this can be written as<br>
</p>
<div class="math">$$\begin{align}  
\rho &amp; \equiv \frac{cov(\vec{a} \cdot \hat{\theta} ,\vec{b} \cdot \vec{T})}{\sqrt{var(\vec{a} \cdot \hat{\theta})var(\vec{b} \cdot \vec{T})}} \\  
&amp;= \frac{\vec{a}^T \cdot \vec{b}}{\left(\vec{a}^T \cdot cov(\hat{\theta}, \hat{\theta}) \cdot \vec{a} \right)^{1/2} \left( \vec{b}^T \cdot cov(\vec{T},\vec{T}) \cdot \vec{b} \right)^{1/2}}\leq 1. \tag{13}  
\end{align}  
$$</div>
<p><br>
The last inequality here follows from Lemma 4. We can find the direction <span class="math">\(\hat{b}\)</span> where the bound above is most tight &#8212; at fixed <span class="math">\(\vec{a}\)</span> &#8212; by maximizing the numerator while holding the denominator fixed in value. Using a Lagrange multiplier to hold <span class="math">\(\left( \vec{b}^T \cdot cov(\vec{T},\vec{T}) \cdot \vec{b} \right) \equiv 1\)</span>, the numerator&#8217;s extremum occurs where<br>
</p>
<div class="math">$$  
\vec{a}^T + 2 \lambda \vec{b}^T \cdot cov(\vec{T},\vec{T}) = 0 \ \ \to \ \ \vec{b}^T = - \frac{1}{2 \lambda} \vec{a}^T \cdot cov(\vec{T}, \vec{T})^{-1}. \tag{14}  
$$</div>
<p><br>
Plugging this form into the prior line, we obtain<br>
</p>
<div class="math">$$  
- \frac{\vec{a}^T \cdot cov(\vec{T},\vec{T})^{-1} \cdot \vec{a}}{\left(\vec{a}^T \cdot cov(\hat{\theta}, \hat{\theta}) \cdot \vec{a} \right)^{1/2} \left(\vec{a}^T \cdot cov(\vec{T},\vec{T})^{-1} \cdot \vec{a} \right)^{1/2}}\leq 1. \tag{15}  
$$</div>
<p><br>
Squaring and rearranging terms, we obtain<br>
</p>
<div class="math">$$  
\vec{a}^T \cdot \left (cov(\hat{\theta},\hat{\theta}) - cov(\vec{T},\vec{T})^{-1} \right ) \cdot \vec{a} \geq 0. \tag{16}  
$$</div>
<p><br>
This holds for any <span class="math">\(\vec{a}\)</span>, implying that <span class="math">\(cov(\hat{\theta}, \hat{\theta}) - cov(\vec{T},\vec{T})^{-1} $ is positive semi-definite -- see (\ref{pd}). Applying Lemma 3, we obtain the result\)</span>^3<span class="math">\(.&nbsp;$\blacksquare\)</span></p>
<p>Thank you for reading &#8212; we hope you&nbsp;enjoyed.</p>
<p>[1] More generally, (\ref{fact}) tells us that an observation similar to (\ref{CRsimple}) holds for any linear combination of the <span class="math">\(\{\theta_i\}\)</span>. Notice also that the proof we provide here could also be applied to any individual <span class="math">\(\theta_i\)</span>, giving <span class="math">\(\sigma^2(\hat{\theta}_i) \geq 1/n \times 1/\langle(\partial_{\theta_i} \log P)^2\rangle\)</span>. This is easier to apply than (\ref{<span class="caps">CR</span>}), but is less&nbsp;stringent.</p>
<p>[2] It might be challenging to intuit the exact function that appears on the right side of <span class="math">\((\ref{CR})\)</span>. However, the appearance of <span class="math">\(\log P\)</span><span class="quo">&#8216;</span>s does make some intuitive sense, as it allows the derivatives involved to measure rates of change relative to typical values, <span class="math">\(\nabla_{\theta} P / P\)</span>.</p>
<p>[3] The discussion here covers the &#8220;standard proof&#8221; of the Cramer-Rao result. Its brilliance is that it allows one to work with scalars. In contrast, when attempting to find my own proof, I began with the fact that all covariance matrices are positive definite. Applying this result to the covariance matrix of a linear combination of <span class="math">\(\hat{\theta}\)</span> and <span class="math">\(\vec{T}\)</span>, one can quickly get to results similar in form to the Cramer-Rao bound, but not quite identical. After significant work, I was eventually able to show that <span class="math">\(\sqrt{cov(\hat{\theta},\hat{\theta})} - 1/\sqrt{cov(\vec{T},\vec{T}) } \geq 0\)</span>. However, I have yet to massage my way to the final result using this approach &#8212; the difficulty being that the matrices involved don&#8217;t commute. By working with scalars from the start, the proof here cleanly avoids all such&nbsp;issues.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>


             
 
                <p id="post-share-links">
    Like this post?  Share on:
    <a href="https://twitter.com/intent/tweet?text=Multivariate%20Cramer-Rao%C2%A0inequality&url=http%3A//efavdb.github.io/multivariate-cramer-rao-bound.html" target="_blank" rel="nofollow noopener noreferrer" title="Share on Twitter">Twitter</a>
    ❄
    <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A//efavdb.github.io/multivariate-cramer-rao-bound.html" target="_blank" rel="nofollow noopener noreferrer" title="Share on Facebook">Facebook</a>
    ❄
    <a href="mailto:?subject=Multivariate%20Cramer-Rao%C2%A0inequality&amp;body=http%3A//efavdb.github.io/multivariate-cramer-rao-bound.html" target="_blank" rel="nofollow noopener noreferrer" title="Share via Email">Email</a>
    </p>

                <hr />
    <div class="author_blurb">
        <a href="" target="_blank" rel="nofollow noopener noreferrer">
            <img src=/wp-content/uploads/2014/12/JonathanLinkedIn.jpg alt="Jonathan Landy Avatar" title="Jonathan Landy">
            <span class="author_name">Jonathan Landy</span>
        </a>
        Jonathan grew up in the midwest and then went to school at Caltech and UCLA. Following this, he did two postdocs, one at UCSB and one at UC Berkeley.  His academic research focused primarily on applications of statistical mechanics, but his professional passion has always been in the mastering, development, and practical application of slick math methods/tools. He worked as a data-scientist at Square for four years and is now working on a quantitative investing startup.
    </div>

            






<section>
    <h6 style="display:none;">Comments</h6>
    <p id="comment-message"> </p>

    <div class="accordion" id="accordion2">
        <div class="accordion-group">
            <div class="accordion-heading">
                <a class="accordion-toggle disqus-comment-count comment-count"
                   data-toggle="collapse"
                   data-parent="#accordion2"
                   data-disqus-identifier="./multivariate-cramer-rao-bound.html"
                   href="./multivariate-cramer-rao-bound.html#comment_thread"
                   id="comment-accordion-toggle">
                    Comments
                </a>
            </div>
            <div id="comment_thread" class="accordion-body collapse">
                <div class="accordion-inner">
                    <div class="comments">
                        <div id="disqus_thread"></div>
                        <script>
    var disqus_shortname = 'EFAVDB';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());

    var disqus_identifier = './multivariate-cramer-rao-bound.html';
    var disqus_url = './multivariate-cramer-rao-bound.html';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>

<noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

            <hr/>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="previous-article">« <a href="./reshaping-data-in-r.html" title="Previous: Reshaping Data in R">Reshaping Data in R</a></li>
                <li class="next-article"><a href="./review-intro-to-big-data-with-spark.html" title="Next: A review of the online course “Introduction to Big Data with Apache Spark”">A review of the online course “Introduction to Big Data with Apache Spark”</a> »</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2015-06-20T09:00:00-07:00">Jun 20, 2015</time>
            <h4>Category</h4>
            <a class="category-link" href="./categories.html#statistics-ref">Statistics</a>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://twitter.com/efavdb" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="Twitter" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1da1f3"/><path fill="#fff" d="M437 152a72 72 0 0 1-40 12 72 72 0 0 0 32-40 72 72 0 0 1-45 17 72 72 0 0 0-122 65 200 200 0 0 1-145-74 72 72 0 0 0 22 94 72 72 0 0 1-32-7 72 72 0 0 0 56 69 72 72 0 0 1-32 1 72 72 0 0 0 67 50 200 200 0 0 1-105 29 200 200 0 0 0 309-179 200 200 0 0 0 35-37"/></svg>
    </a>
    <a href="https://github.com/efavdb" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
    <a href="https://www.youtube.com/channel/UClfvjoSiu0VvWOh5OpnuusA" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="YouTube" role="img" viewBox="0 0 512 512" fill="#ed1d24"><rect width="512" height="512" rx="15%"/><path d="m427 169c-4-15-17-27-32-31-34-9-239-10-278 0-15 4-28 16-32 31-9 38-10 135 0 174 4 15 17 27 32 31 36 10 241 10 278 0 15-4 28-16 32-31 9-36 9-137 0-174" fill="#fff"/><path d="m220 203v106l93-53"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
                        <button onclick="topFunction()" id="myBtn" title="Go to top">&#x25B2;</button>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>

    <div>
        <span class="site-name">EFAVDB</span> - Everybody's Favorite Data Blog
    </div>



    <!-- <div id="fpowered"> -->
    <!--     Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a> -->
    <!--     Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a> -->
    <!--      -->
    <!-- </div> -->
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>
        <script>
            //** Scroll to top button **
            //Get the button:
            mybutton = document.getElementById("myBtn");

            // When the user scrolls down 30px from the top of the document, show the button
            window.onscroll = function() {scrollFunction()};

            function scrollFunction() {
              if (document.body.scrollTop > 30 || document.documentElement.scrollTop > 30) {
                mybutton.style.display = "block";
              } else {
                mybutton.style.display = "none";
              }
            }

            // When the user clicks on the button, scroll to the top of the document
            function topFunction() {
              document.body.scrollTop = 0; // For Safari
              document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>