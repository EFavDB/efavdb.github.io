<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Cathy Yeh" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">


<meta property="og:title" content="Getting started in reinforcement learning "/>
<meta property="og:url" content="../pages/rl-resources.html" />
<meta property="og:description" content="[TOC] Last updated: 2020-07-12 We’ve collected some resources for getting started in reinforcement learning (RL). Comments or suggestions are welcome! A significant part of modeling in RL takes place outside of neural networks, with nets being just one component. We therefore recommend starting with classic RL theory before proceeding …" />
<meta property="og:site_name" content="EFAVDB" />
<meta property="og:article:author" content="Cathy Yeh" />
<meta property="og:article:published_time" content="2020-04-25T00:00:00-07:00" />
<meta name="twitter:title" content="Getting started in reinforcement learning ">
<meta name="twitter:description" content="[TOC] Last updated: 2020-07-12 We’ve collected some resources for getting started in reinforcement learning (RL). Comments or suggestions are welcome! A significant part of modeling in RL takes place outside of neural networks, with nets being just one component. We therefore recommend starting with classic RL theory before proceeding …">

        <title>Getting started in reinforcement learning  · EFAVDB
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Fira+Sans:300,400,700" rel="stylesheet" type='text/css' />
        <link href="https://fonts.googleapis.com/css?family=Cardo:400,700" rel="stylesheet" type='text/css' />        
        <link rel="stylesheet" type="text/css" href="../theme/css/elegant.prod.css" media="screen">
        <link rel="stylesheet" type="text/css" href="../theme/css/custom.css" media="screen">


        <link rel="apple-touch-icon" sizes="180x180" href="../images/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="../images/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="../images/favicon-16x16.png">
        <link rel="manifest" href="../images/site.webmanifest">
        <link rel="mask-icon" href="../images/safari-pinned-tab.svg" color="#5bbad5">
        <meta name="msapplication-TileColor" content="#da532c">
        <meta name="theme-color" content="#ffffff">
    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="../"><span class=site-name>EFAVDB</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       ..
                                    >Home</a>
                                </li>
                                <li ><a href="../pages/authors.html">Authors</a></li>
                                <li ><a href="../categories.html">Categories</a></li>
                                <li ><a href="../tags.html">Tags</a></li>
                                <li ><a href="../archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="../search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article>
<div class="row-fluid">
    <header class="page-header span8 offset2">
    <h1><a href="../pages/rl-resources.html"> Getting started in reinforcement&nbsp;learning  </a></h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">

            <p>[<span class="caps">TOC</span>]</p>
<p><em>Last updated:&nbsp;2020-07-12</em></p>
<p>We’ve collected some resources for getting started in reinforcement learning (<span class="caps">RL</span>).  Comments or suggestions are&nbsp;welcome!</p>
<p>A significant part of modeling in <span class="caps">RL</span> takes place <em>outside</em> of neural networks, with nets being just one component.  We therefore recommend starting with classic <span class="caps">RL</span> theory before proceeding to deep <span class="caps">RL</span>.</p>
<p>Roughly in order of recommended&nbsp;progression:</p>
<h2>Quick surveys of <span class="caps">RL</span></h2>
<p>Before embarking on a full course of study, get some high-level orientation from these lively blog&nbsp;posts:</p>
<ul>
<li><a href="https://www.alexirpan.com/2018/02/14/rl-hard.html">Deep reinforcement learning doesn’t work yet</a>, blog by Alex Irpan - good look at current problems in deep <span class="caps">RL</span>, many entertaining examples (doesn’t go into details of&nbsp;algorithms)</li>
<li><a href="http://karpathy.github.io/2016/05/31/rl/">Pong from pixels</a>, blog by Andrej Karpathy - goes into details of implementing policy gradient algorithm on the pong Atari game to illustrate <span class="caps">RL</span> in action, accompanied by sweet, simple&nbsp;code</li>
<li><a href="https://www.youtube.com/watch?v=9EN_HoEk3KY">OpenAI Meta-Learning and Self-Play</a>, video lecture by Ilya Sutskever &#8212; introduces core ideas in <span class="caps">RL</span> simply and with great insight, leading to research directions (still at a high&nbsp;level)</li>
</ul>
<h2>Foundations</h2>
<p>Do in&nbsp;parallel:</p>
<ul>
<li><strong>David Silver’s <span class="caps">UCL</span> course on <span class="caps">RL</span></strong> <a href="https://www.davidsilver.uk/teaching/">video lectures</a> - condenses important concepts from Sutton and Barto while maintaining continuity, clear and insightful&nbsp;explanations</li>
<li><strong>Introduction to Reinforcement Learning</strong>, Sutton and Barto’s (S&amp;B) classic text, free <a href="http://incompleteideas.net/book/RLbook2018.pdf">online copy&nbsp;available</a></li>
</ul>
<p>Comments:</p>
<ul>
<li>David Silver’s course closely follows S&amp;B up through about lecture 5.  We recommend watching each video lecture first, then reviewing the corresponding material in the text&nbsp;afterwards.</li>
<li>Function approximation, where neural networks (deep <span class="caps">RL</span>) become relevant, is not until lecture 6.
Silver’s course doesn’t include links to exercises, but we’ve provided code for an example model from his first few lectures (discussed in our blog post <a href="https://www.efavdb.com/intro-rl-toy-example">introducing <span class="caps">RL</span></a> and <a href="https://www.efavdb.com/reinforcement-learning-dynamic-programming">solving</a> the problem with dynamic&nbsp;programming).</li>
</ul>
<h2>Additional video&nbsp;lectures</h2>
<p><strong>Sergey Levine’s Berkeley Deep <span class="caps">RL</span> course</strong>, <a href="http://rail.eecs.berkeley.edu/deeprlcourse/"><span class="caps">CS285</span></a></p>
<p>Comments:</p>
<ul>
<li>Levine’s course is more advanced than Silver&#8217;s, with a brisker approach to deep <span class="caps">RL</span> (less time spent on classical <span class="caps">RL</span> basics).  Like Silver, Levine is a fantastic lecturer and provides a valuable complementary perspective, e.g. more discussion about convergence properties of algorithms, additional intuition on why policy gradients are high variance.  We enjoyed interleaving the Silver and Levine lectures to get multiple takes on the same&nbsp;topics.</li>
<li>The content from the first half of Levine’s course overlaps with Silver’s, while the second half of the course moves beyond core concepts and brings you to the cutting edge in <span class="caps">RL</span>.</li>
</ul>
<h2>Exercises and&nbsp;implementations</h2>
<ul>
<li><strong>Denny Britz’s <a href="https://github.com/dennybritz/reinforcement-learning">reinforcement learning repo</a></strong> - instructional exercises and self-contained implementations.  A great accompaniment to David Silver’s course and Sutton and&nbsp;Barto.</li>
<li><strong>OpenAI’s <a href="https://spinningup.openai.com/en/latest/">Spinning up in <span class="caps">RL</span></a></strong> - self-contained, lightweight implementations of different <span class="caps">RL</span> algorithms<ul>
<li>“Introduction to <span class="caps">RL</span>” section is a bit terse for a first exposure to <span class="caps">RL</span>, but docs are an excellent reference otherwise, particularly if you’re ready to start implementing deep <span class="caps">RL</span>&nbsp;algorithms.</li>
<li>Includes instructive usage of auxiliary tools for deep learning, like <a href="https://github.com/openai/spinningup/blob/master/spinup/algos/pytorch/vpg/vpg.py#L183">logging</a> and <span class="caps">MPI</span> <a href="https://github.com/openai/spinningup/blob/master/spinup/algos/pytorch/vpg/vpg.py#L180">parallelization</a></li>
</ul>
</li>
<li><strong><a href="https://github.com/openai/gym">OpenAI gym</a></strong> - a toolkit for creating custom environments for running your <span class="caps">RL</span> algorithms, including a good number of <a href="https://gym.openai.com/envs/">ready-to-go implementations</a>. The <span class="caps">API</span> is simple and&nbsp;intuitive.</li>
</ul>
<h2>Miscellaneous</h2>
<ul>
<li><a href="https://openreview.net/">Openreview.net</a> - it’s hard to place the impact/context of the latest research when you’re just coming to a field, so the publicly available feedback from experts reviewing the papers is&nbsp;invaluable</li>
<li><strong>Benchmarks and baselines</strong> - not sure if your implementation of an <span class="caps">RL</span> algorithm is performing as expected?  Check out the rl-baselines-zoo <a href="https://github.com/araffin/rl-baselines-zoo/blob/master/benchmark.md">benchmarks</a>, achieved from standardized implementations of <span class="caps">RL</span> algorithms using <a href="https://github.com/hill-a/stable-baselines">Stable Baselines</a>.</li>
</ul>
            






        </div>
    </div>
    </article>
                        <button onclick="topFunction()" id="myBtn" title="Go to top">&#x25B2;</button>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>

    <div>
        <span class="site-name"><a href= ..>EFAVDB</span> - Everybody's Favorite Data Blog</a>
    </div>



    <!-- <div id="fpowered"> -->
    <!--     Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a> -->
    <!--     Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a> -->
    <!--      -->
    <!-- </div> -->
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>
        <script>
            //** Scroll to top button **
            //Get the button:
            mybutton = document.getElementById("myBtn");

            // When the user scrolls down 30px from the top of the document, show the button
            window.onscroll = function() {scrollFunction()};

            function scrollFunction() {
              if (document.body.scrollTop > 30 || document.documentElement.scrollTop > 30) {
                mybutton.style.display = "block";
              } else {
                mybutton.style.display = "none";
              }
            }

            // When the user clicks on the button, scroll to the top of the document
            function topFunction() {
              document.body.scrollTop = 0; // For Safari
              document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>