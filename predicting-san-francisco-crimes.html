<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Damien RJ" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Case studies, " />

<meta property="og:title" content="Machine learning to predict San Francisco crime "/>
<meta property="og:url" content="https://efavdb.com/predicting-san-francisco-crimes" />
<meta property="og:description" content="In today’s post, we document our submission to the recent Kaggle competition aimed at predicting the category of San Francisco crimes, given only their time and location of occurrence. As a reminder, Kaggle is a site where one can compete with other data scientists on various data challenges. We …" />
<meta property="og:site_name" content="EFAVDB" />
<meta property="og:article:author" content="Damien RJ" />
<meta property="og:article:published_time" content="2015-07-20T03:01:00-07:00" />
<meta name="twitter:title" content="Machine learning to predict San Francisco crime ">
<meta name="twitter:description" content="In today’s post, we document our submission to the recent Kaggle competition aimed at predicting the category of San Francisco crimes, given only their time and location of occurrence. As a reminder, Kaggle is a site where one can compete with other data scientists on various data challenges. We …">

        <title>Machine learning to predict San Francisco crime  · EFAVDB
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Fira+Sans:300,400,700" rel="stylesheet" type='text/css' />
        <link href="https://fonts.googleapis.com/css?family=Cardo:400,700" rel="stylesheet" type='text/css' />        
        <link rel="stylesheet" type="text/css" href="https://efavdb.com/theme/css/elegant.prod.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://efavdb.com/theme/css/custom.css" media="screen">

        <link href="https://efavdb.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="EFAVDB - Full Atom Feed" />
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-57405119-1', 'auto');
    ga('send', 'pageview');
</script>


        <link rel="apple-touch-icon" sizes="180x180" href="https://efavdb.com/images/apple-touch-icon.png">
        <link rel="icon" type="image/png" sizes="32x32" href="https://efavdb.com/images/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="https://efavdb.com/images/favicon-16x16.png">
        <link rel="manifest" href="https://efavdb.com/images/site.webmanifest">
        <link rel="mask-icon" href="https://efavdb.com/images/safari-pinned-tab.svg" color="#5bbad5">
        <meta name="msapplication-TileColor" content="#da532c">
        <meta name="theme-color" content="#ffffff">
    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://efavdb.com/"><span class=site-name>EFAVDB</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://efavdb.com
                                    >Home</a>
                                </li>
                                <li ><a href="https://efavdb.com/pages/authors.html">Authors</a></li>
                                <li ><a href="https://efavdb.com/categories">Categories</a></li>
                                <li ><a href="https://efavdb.com/tags">Tags</a></li>
                                <li ><a href="https://efavdb.com/archives">Archives</a></li>
                                <li><form class="navbar-search" action="https://efavdb.com/search" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span8 offset2">
        <h1>
            <a href="https://efavdb.com/predicting-san-francisco-crimes">
                Machine learning to predict San Francisco&nbsp;crime
            </a>
        </h1>
    </header>
    <div class="span2"></div>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>In today&#8217;s post, we document our submission to the recent <a href="https://www.kaggle.com/c/sf-crime">Kaggle</a> competition aimed at predicting the category of San Francisco crimes, given only their time and location of occurrence. As a reminder, Kaggle is a site where one can compete with other data scientists on various data challenges.  We took this competition as an opportunity to explore the Naive Bayes algorithm. With the few steps discussed below, we were able to quickly move from the middle of the pack to the top 33% on the competition leader board, all the while continuing with this simple&nbsp;model!</p>
<h2>Introduction</h2>
<p>As in all cities, crime is a reality San Francisco: Everyone who lives in San Francisco seems to know someone whose car window has been smashed in, or whose bicycle was stolen within the past year or two. Even Prius&#8217; car batteries are apparently considered <a href="http://abc7news.com/news/exclusive-car-battery-thefts-from-hybrid-cars-on-the-rise-in-san-francisco-/725532/">fair game</a> by the city&#8217;s diligent thieves.  The challenge we tackle today involves attempting to guess the class of a crime committed within the city, given the time and location it took place. Such studies are representative of efforts by many police forces today: Using machine learning approaches, one can get an improved understanding of which crimes occur where and when in a city &#8212; this then allows for better, <a href="http://www.forbes.com/sites/emc/2014/06/03/data-analysis-helps-police-departments-fight-crime/">dynamic allocation of police resources</a>. To aid in the <span class="caps">SF</span> <a href="https://www.kaggle.com/c/sf-crime">challenge</a>, Kaggle has provided about 12 years of crime reports from all over the city &#8212; a data set that is pretty interesting to comb&nbsp;through.</p>
<p>Here, we outline our approach to tackling this problem, using the Naive Bayes classifier. This is one of the simplest classification algorithms, the essential ingredients of which include combining <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" title="Bayes' theorem">Bayes&#8217; theorem</a> with an independence assumption on the features (this is the &#8220;naive&#8221; part).  Although simple, it is still a popular method for text categorization. For example, using word frequencies as features, this approach can accurately classify emails as spam, or whether a particular a piece of text was written by a specific author.  In fact, with careful preprocessing, the algorithm is often <a href="http://people.csail.mit.edu/jrennie/papers/icml03-nb.pdf">competitive</a> with more advanced methods, including support vector&nbsp;machines.</p>
<h2><strong>Loading package and&nbsp;data</strong></h2>
<p>Below, we show the relevant commands needed to load all the packages and training/test data we will be using. As in previous posts, we will work with <a href="http://pandas.pydata.org/">Pandas</a> for quick and easy data loading and wrangling. We will be having a post dedicated to Pandas in the near future, so stay tuned! We start off with using the parse_dates method to convert the Dates column of our provided data &#8212; which can be downloaded <a href="https://www.kaggle.com/c/sf-crime/data">here</a>&#8212; from string to datetime&nbsp;format.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">log_loss</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">BernoulliNB</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1">#Load Data with pandas, and parse the first column into datetime</span>
<span class="n">train</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;train.csv&#39;</span><span class="p">,</span> <span class="n">parse_dates</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Dates&#39;</span><span class="p">])</span>
<span class="kp">test</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;test.csv&#39;</span><span class="p">,</span> <span class="n">parse_dates</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Dates&#39;</span><span class="p">])</span>
</pre></div>


<p>The training data provided contains the following&nbsp;fields:</p>
<p><strong><em>Date</em></strong> -  date + timestamp
<strong><em>Category</em></strong> - The type of crime, Larceny, etc.
<strong><em>Descript</em></strong> - A more detailed description of the crime.
<strong><em>DayOfWeek</em></strong> - Day of crime: Monday, Tuesday, etc.
<strong><em>PdDistrict </em></strong>- Police department district.
<strong><em>Resolution</em></strong>- What was the outcome, Arrest, Unfounded, None, etc.
<strong><em>Address</em></strong> - Street address of crime.
<strong><em>X and Y</em></strong> - <span class="caps">GPS</span> coordinates of&nbsp;crime.</p>
<p>As we mentioned earlier, the provided data spans almost 12 years, and both the training data set and the testing data set each have about 900k records. At this point we have all the data in memory. However, the majority of this data is categorical in nature, and so will require some more&nbsp;preprocessing.</p>
<h2>How to handle categorical&nbsp;data</h2>
<p>Many machine learning algorithms &#8212; including that which we apply below &#8212; will not accept categorical, or text, features. What is the best way to convert such data into numerical values? A natural idea is to convert each unique string to a unique value.  For example, in our data set we might take the crime category value to correspond to one numerical feature, with Larceny set to 1, Homicide to 2, etc.  However, this scheme can cause problems for many algorithms, because they will incorrectly assume that nearby numerical values imply some sort of similarity between the underlying categorical&nbsp;values.</p>
<p>To avoid the problem noted above, we will instead binarize our categorical data, using vectors of 1&#8217;s and 0&#8217;s. For example, we will&nbsp;write</p>
<div class="highlight"><pre><span></span><span class="err">larceny = 1,0,0,0,...</span>
<span class="err">homicide = 0,1,0,0,...</span>
<span class="err">prostitution  = 0,0,1,0,...</span>
<span class="err">...</span>
</pre></div>


<p>There are a variety of methods to do this encoding, but Pandas has a particularly nice method called <a href="http://pandas.pydata.org/pandas-docs/version/0.13.1/generated/pandas.get_dummies.html">get_dummies()</a> that can go straight from your column of text to a binarized array.  Below, we also convert the crime category labels to integer values using the method <a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html">LabelEncoder</a>, and use Pandas to extract the hour from each time point. We then convert the districts, weekday, and hour into binarized arrays and combine them into a new dataframe. <strong> </strong> We then split up the train_data into a training and validation set so that we have a way of accessing the model performance while leaving the test data&nbsp;untouched.</p>
<div class="highlight"><pre><span></span><span class="o">#</span><span class="k">Convert</span> <span class="n">crime</span> <span class="n">labels</span> <span class="k">to</span> <span class="n">numbers</span>
<span class="n">le_crime</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">crime</span> <span class="o">=</span> <span class="n">le_crime</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">Category</span><span class="p">)</span>

<span class="o">#</span><span class="k">Get</span> <span class="n">binarized</span> <span class="n">weekdays</span><span class="p">,</span> <span class="n">districts</span><span class="p">,</span> <span class="k">and</span> <span class="n">hours</span><span class="p">.</span>
<span class="n">days</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">DayOfWeek</span><span class="p">)</span>
<span class="n">district</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">PdDistrict</span><span class="p">)</span>
<span class="n">hour</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">Dates</span><span class="p">.</span><span class="n">dt</span><span class="p">.</span><span class="n">hour</span>
<span class="n">hour</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">hour</span><span class="p">)</span>

<span class="o">#</span><span class="n">Build</span> <span class="k">new</span> <span class="nb">array</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">hour</span><span class="p">,</span> <span class="n">days</span><span class="p">,</span> <span class="n">district</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;crime&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">crime</span>

<span class="o">#</span><span class="n">Repeat</span> <span class="k">for</span> <span class="n">test</span> <span class="k">data</span>
<span class="n">days</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">test</span><span class="p">.</span><span class="n">DayOfWeek</span><span class="p">)</span>
<span class="n">district</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">test</span><span class="p">.</span><span class="n">PdDistrict</span><span class="p">)</span>

<span class="n">hour</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">Dates</span><span class="p">.</span><span class="n">dt</span><span class="p">.</span><span class="n">hour</span>
<span class="n">hour</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">hour</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">([</span><span class="n">hour</span><span class="p">,</span> <span class="n">days</span><span class="p">,</span> <span class="n">district</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">training</span><span class="p">,</span> <span class="n">validation</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="p">.</span><span class="mi">60</span><span class="p">)</span>
</pre></div>


<h2><strong>Model&nbsp;development</strong></h2>
<p>For this competition the metric used to rate the performance of the model is the multi-class <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html">log_loss</a> &#8212; smaller values of this loss correspond to improved&nbsp;performance.</p>
<h4>First&nbsp;pass</h4>
<p>For our first quick pass, we used just the day of the week and district for features in our classifier training. We also carried out a Logistic Regression (<span class="caps">LR</span>) on the data in order to get a feel for how the Naive Bayes (<span class="caps">NB</span>) model was performing. The results from the <span class="caps">NB</span> model gave us a log-loss of 2.62, while <span class="caps">LR</span> after tuning was able to give 2.62. However, <span class="caps">LR</span> took 60 seconds to run, while <span class="caps">NB</span> took only 1.5 seconds! As a reference, the current top score on the leader board is about 2.27, while the worst is around 35. Not bad&nbsp;performance!</p>
<div class="highlight"><pre><span></span><span class="n">features</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">&#39;Friday&#39;, &#39;Monday&#39;, &#39;Saturday&#39;, &#39;Sunday&#39;, &#39;Thursday&#39;, &#39;Tuesday&#39;,</span>
<span class="n">&#39;Wednesday&#39;, &#39;BAYVIEW&#39;, &#39;CENTRAL&#39;, &#39;INGLESIDE&#39;, &#39;MISSION&#39;,</span>
<span class="n">&#39;NORTHERN&#39;, &#39;PARK&#39;, &#39;RICHMOND&#39;, &#39;SOUTHERN&#39;, &#39;TARAVAL&#39;, &#39;TENDERLOIN&#39;</span><span class="o">]</span><span class="w"></span>

<span class="n">training</span><span class="p">,</span><span class="w"> </span><span class="n">validation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_test_split</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span><span class="w"> </span><span class="n">train_size</span><span class="o">=</span><span class="mf">.60</span><span class="p">)</span><span class="w"></span>
<span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BernoulliNB</span><span class="p">()</span><span class="w"></span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="o">[</span><span class="n">features</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">[</span><span class="n">&#39;crime&#39;</span><span class="o">]</span><span class="p">)</span><span class="w"></span>
<span class="n">predicted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="k">array</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">validation</span><span class="o">[</span><span class="n">features</span><span class="o">]</span><span class="p">))</span><span class="w"></span>
<span class="n">log_loss</span><span class="p">(</span><span class="n">validation</span><span class="o">[</span><span class="n">&#39;crime&#39;</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">predicted</span><span class="p">)</span><span class="w"></span>

<span class="n">#Logistic</span><span class="w"> </span><span class="n">Regression</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">comparison</span><span class="w"></span>
<span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">.01</span><span class="p">)</span><span class="w"></span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="o">[</span><span class="n">features</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">training</span><span class="o">[</span><span class="n">&#39;crime&#39;</span><span class="o">]</span><span class="p">)</span><span class="w"></span>
<span class="n">predicted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="k">array</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">validation</span><span class="o">[</span><span class="n">features</span><span class="o">]</span><span class="p">))</span><span class="w"></span>
<span class="n">log_loss</span><span class="p">(</span><span class="n">validation</span><span class="o">[</span><span class="n">&#39;crime&#39;</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">predicted</span><span class="p">)</span><span class="w"></span>
</pre></div>


<h4>Submission&nbsp;code</h4>
<div class="highlight"><pre><span></span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">BernoulliNB</span><span class="p">()</span><span class="w"></span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_data</span><span class="o">[</span><span class="n">features</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">train_data</span><span class="o">[</span><span class="n">&#39;crime&#39;</span><span class="o">]</span><span class="p">)</span><span class="w"></span>
<span class="n">predicted</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">model</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test_data</span><span class="o">[</span><span class="n">features</span><span class="o">]</span><span class="p">)</span><span class="w"></span>

<span class="n">#Write</span><span class="w"> </span><span class="n">results</span><span class="w"></span>
<span class="k">result</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span><span class="w"> </span><span class="n">columns</span><span class="o">=</span><span class="n">le_crime</span><span class="p">.</span><span class="n">classes_</span><span class="p">)</span><span class="w"></span>
<span class="k">result</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;testResult.csv&#39;</span><span class="p">,</span><span class="w"> </span><span class="k">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">True</span><span class="p">,</span><span class="w"> </span><span class="n">index_label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;Id&#39;</span><span class="w"> </span><span class="p">)</span><span class="w"></span>
</pre></div>


<p>With the above model performing well, we used our code to write out our predictions on the test set to csv format, and submitted this to Kaggle. It turns out we got a score of 2.61 which is slightly better than our validation set estimate. The was a good enough score to put us in the to 50%. Pretty good for a first&nbsp;try!</p>
<h4>Second&nbsp;pass</h4>
<p>To improve the model further, we next added the time to the feature list used in training. This clearly provides some relevant information, as some types of crime happen more during the day than the night. For example, we expect public drunkenness to probably go up in the late evening.  Adding this feature we were able to push our log-loss score down to 2.58 &#8212; quick and easy progress!  As a side note, we also tried leaving the hours as a continuous variable, but this did not lead to any score improvements.  After training on the whole data set again, we also get 2.58 on the test date. This moved us up another 32 spots, giving a final placement of&nbsp;76/226!</p>
<div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Friday&#39;</span><span class="p">,</span> <span class="s1">&#39;Monday&#39;</span><span class="p">,</span> <span class="s1">&#39;Saturday&#39;</span><span class="p">,</span> <span class="s1">&#39;Sunday&#39;</span><span class="p">,</span> <span class="s1">&#39;Thursday&#39;</span><span class="p">,</span> <span class="s1">&#39;Tuesday&#39;</span><span class="p">,</span>
<span class="s1">&#39;Wednesday&#39;</span><span class="p">,</span> <span class="s1">&#39;BAYVIEW&#39;</span><span class="p">,</span> <span class="s1">&#39;CENTRAL&#39;</span><span class="p">,</span> <span class="s1">&#39;INGLESIDE&#39;</span><span class="p">,</span> <span class="s1">&#39;MISSION&#39;</span><span class="p">,</span>
<span class="s1">&#39;NORTHERN&#39;</span><span class="p">,</span> <span class="s1">&#39;PARK&#39;</span><span class="p">,</span> <span class="s1">&#39;RICHMOND&#39;</span><span class="p">,</span> <span class="s1">&#39;SOUTHERN&#39;</span><span class="p">,</span> <span class="s1">&#39;TARAVAL&#39;</span><span class="p">,</span> <span class="s1">&#39;TENDERLOIN&#39;</span><span class="p">]</span>

<span class="n">features2</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="k">in</span> <span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">24</span><span class="p">)]</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">features</span> <span class="o">+</span> <span class="n">features2</span>
</pre></div>


<h2>Discussion</h2>
<p>Although Naive Bayes is a fairly simple model, properly wielded it can give great results.  In fact, in this competition our results were competitive with teams who were using much more complicated models, e.g. neural nets. We also learned a few other interesting things here: For example, Pandas&#8217; get_dummies() method looks like it will be a huge timesaver when dealing with categorical data. Till next time &#8212; keep your Prius safe!
<a href="https://github.com/EFavDB/SF-Crime" title="GitHub Repo"><img alt="Open GitHub Repo" src="https://efavdb.com/wp-content/uploads/2015/03/GitHub_Logo.png"></a></p>


             
 
                <p id="post-share-links">
    Like this post?  Share on:
    <a href="https://twitter.com/intent/tweet?text=Machine%20learning%20to%20predict%20San%20Francisco%C2%A0crime&url=https%3A//efavdb.com/predicting-san-francisco-crimes" target="_blank" rel="nofollow noopener noreferrer" title="Share on Twitter">Twitter</a>
    ❄
    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//efavdb.com/predicting-san-francisco-crimes" target="_blank" rel="nofollow noopener noreferrer" title="Share on Facebook">Facebook</a>
    ❄
    <a href="mailto:?subject=Machine%20learning%20to%20predict%20San%20Francisco%C2%A0crime&amp;body=https%3A//efavdb.com/predicting-san-francisco-crimes" target="_blank" rel="nofollow noopener noreferrer" title="Share via Email">Email</a>
    </p>

                <hr />
    <div class="author_blurb">
        <a href="" target="_blank" rel="nofollow noopener noreferrer">
            <img src=/wp-content/uploads/2014/12/headshot.jpg alt="Damien RJ Avatar" title="Damien RJ">
            <span class="author_name">Damien RJ</span>
        </a>
        Damien is a highly experienced researcher with a background in clinical and applied research. Like JSL, he got his PhD at UCLA. He has many years of experience working with imaging, and has a particularly strong background in image segmentation, registration, detection, data analysis, and more recently machine learning. He now works as a data-scientist at Square in San Francisco.
    </div>

            






<section>
    <h6 style="display:none;">Comments</h6>
    <p id="comment-message"> </p>

    <div class="accordion" id="accordion2">
        <div class="accordion-group">
            <div class="accordion-heading">
                <a class="accordion-toggle disqus-comment-count comment-count"
                   data-toggle="collapse"
                   data-parent="#accordion2"
                   data-disqus-identifier="https://efavdb.com/predicting-san-francisco-crimes"
                   href="https://efavdb.com/predicting-san-francisco-crimes#comment_thread"
                   id="comment-accordion-toggle">
                    Comments
                </a>
            </div>
            <div id="comment_thread" class="accordion-body collapse">
                <div class="accordion-inner">
                    <div class="comments">
                        <div id="disqus_thread"></div>
                        <script>
    var disqus_shortname = 'efavdb2';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());

    var disqus_identifier = 'https://efavdb.com/predicting-san-francisco-crimes';
    var disqus_url = 'https://efavdb.com/predicting-san-francisco-crimes';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>

<noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

            <hr/>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="previous-article">« <a href="https://efavdb.com/ranking-revisited" title="Previous: How not to sort by average rating, revisited">How not to sort by average rating, revisited</a></li>
                <li class="next-article"><a href="https://efavdb.com/leave-one-out-cross-validation" title="Next: Leave-one-out cross-validation">Leave-one-out cross-validation</a> »</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2015-07-20T03:01:00-07:00">Jul 20, 2015</time>
            <h4>Category</h4>
            <a class="category-link" href="https://efavdb.com/categories#case-studies-ref">Case studies</a>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://twitter.com/efavdb" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="Twitter" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1da1f3"/><path fill="#fff" d="M437 152a72 72 0 0 1-40 12 72 72 0 0 0 32-40 72 72 0 0 1-45 17 72 72 0 0 0-122 65 200 200 0 0 1-145-74 72 72 0 0 0 22 94 72 72 0 0 1-32-7 72 72 0 0 0 56 69 72 72 0 0 1-32 1 72 72 0 0 0 67 50 200 200 0 0 1-105 29 200 200 0 0 0 309-179 200 200 0 0 0 35-37"/></svg>
    </a>
    <a href="https://github.com/efavdb" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
    <a href="https://www.youtube.com/channel/UClfvjoSiu0VvWOh5OpnuusA" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="YouTube" role="img" viewBox="0 0 512 512" fill="#ed1d24"><rect width="512" height="512" rx="15%"/><path d="m427 169c-4-15-17-27-32-31-34-9-239-10-278 0-15 4-28 16-32 31-9 38-10 135 0 174 4 15 17 27 32 31 36 10 241 10 278 0 15-4 28-16 32-31 9-36 9-137 0-174" fill="#fff"/><path d="m220 203v106l93-53"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
                        <button onclick="topFunction()" id="myBtn" title="Go to top">&#x25B2;</button>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>

    <div>
        <span class="site-name">EFAVDB</span> - Everybody's Favorite Data Blog
    </div>



    <!-- <div id="fpowered"> -->
    <!--     Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a> -->
    <!--     Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a> -->
    <!--      -->
    <!-- </div> -->
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>
        <script>
            //** Scroll to top button **
            //Get the button:
            mybutton = document.getElementById("myBtn");

            // When the user scrolls down 30px from the top of the document, show the button
            window.onscroll = function() {scrollFunction()};

            function scrollFunction() {
              if (document.body.scrollTop > 30 || document.documentElement.scrollTop > 30) {
                mybutton.style.display = "block";
              } else {
                mybutton.style.display = "none";
              }
            }

            // When the user clicks on the button, scroll to the top of the document
            function topFunction() {
              document.body.scrollTop = 0; // For Safari
              document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>