<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Jonathan Landy" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="methods, Methods, Theory, " />

<meta property="og:title" content="Machine Learning Methods: Classification without negative examples "/>
<meta property="og:url" content="https://efavdb.com/methods-regression-without-negative-examples" />
<meta property="og:description" content="Here, we discuss some methods for carrying out classification when only positive examples are available. The latter half of our discussion borrows heavily from W.S. Lee and B. Liu, Proc. ICML-2003 (2003), which we supplement somewhat. Generic logistic regression Logistic regression is a commonly used tool for estimating …" />
<meta property="og:site_name" content="EFAVDB" />
<meta property="og:article:author" content="Jonathan Landy" />
<meta property="og:article:published_time" content="2014-12-20T09:58:00-08:00" />
<meta name="twitter:title" content="Machine Learning Methods: Classification without negative examples ">
<meta name="twitter:description" content="Here, we discuss some methods for carrying out classification when only positive examples are available. The latter half of our discussion borrows heavily from W.S. Lee and B. Liu, Proc. ICML-2003 (2003), which we supplement somewhat. Generic logistic regression Logistic regression is a commonly used tool for estimating …">

        <title>Machine Learning Methods: Classification without negative examples  · EFAVDB
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Fira+Sans:300,400,700" rel="stylesheet" type='text/css' />
        <link href="https://fonts.googleapis.com/css?family=Cardo:400,700" rel="stylesheet" type='text/css' />        
        <link rel="stylesheet" type="text/css" href="https://efavdb.com/theme/css/elegant.prod.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://efavdb.com/theme/css/custom.css" media="screen">

        <link href="https://efavdb.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="EFAVDB - Full Atom Feed" />
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-57405119-1', 'auto');
    ga('send', 'pageview');
</script>


    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://efavdb.com/"><span class=site-name>EFAVDB</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://efavdb.com
                                    >Home</a>
                                </li>
                                <li ><a href="https://efavdb.com/pages/authors.html">Authors</a></li>
                                <li ><a href="https://efavdb.com/categories">Categories</a></li>
                                <li ><a href="https://efavdb.com/tags">Tags</a></li>
                                <li ><a href="https://efavdb.com/archives">Archives</a></li>
                                <li><form class="navbar-search" action="https://efavdb.com/search" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span8 offset2">
        <h1>
            <a href="https://efavdb.com/methods-regression-without-negative-examples">
                Machine Learning Methods: Classification without negative&nbsp;examples
            </a>
        </h1>
    </header>
    <div class="span2"></div>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>Here, we discuss some methods for carrying out classification when only positive examples are available. The latter half of our discussion borrows heavily from <span class="caps">W.S.</span> Lee and B. Liu, Proc. <span class="caps">ICML</span>-2003 (2003), which we supplement&nbsp;somewhat.  </p>
<h2>Generic logistic&nbsp;regression</h2>
<p><a href="http://en.wikipedia.org/wiki/Logistic_regression">Logistic regression</a> is a commonly used tool for estimating the level sets of a Boolean function <span class="math">\(y\)</span> on a set of feature vectors <span class="math">\(\textbf{F}\)</span>: In a sense, you can think of it as a method for playing the game &#8220;Battleship&#8221; on whatever data set you&#8217;re interested in. Its application requires knowledge of the <span class="math">\(\{(\textbf{f}_i,y_i)\}\)</span> pairs on a training set <span class="math">\(\textbf{E} \subseteq \textbf{F}\)</span>, with label <span class="math">\(y_i = 0,1\)</span> for negative and positive examples, respectively. Given these training examples, logistic regression estimates for arbitrary feature vector <span class="math">\(\textbf{f}\)</span>,<br>
</p>
<div class="math">\begin{eqnarray}
h(\textbf{f}) = \frac{1}{1 + \exp \left [ - \textbf{T} \cdot \textbf{f} \right]} \approx y \tag{1}
\end{eqnarray}</div>
<p>
where the coefficient vector <span class="math">\(\textbf{T}\)</span> is taken to be that vector that minimizes<br>
</p>
<div class="math">\begin{eqnarray}\tag{2}
J(h) \equiv -\frac{1}{\vert \textbf{E} \vert}\sum_{i=1}^{\vert \textbf{E} \vert} y_i \log(h_i) + (1-y_i) \log(1- h_i) + \frac{\Lambda}{2}\sum_j T_j^2,
\end{eqnarray}</div>
<p>
a convex cost function that strongly penalizes poor estimates on the training&nbsp;set.</p>
<h2>Problem statement: no negative&nbsp;examples</h2>
<p>Consider now a situation where all training examples given are positive &#8212; i.e., no negative examples are available. One realistic realization of this scenario might involve a simple data set of movies already viewed by some Netflix customer. From this information, one would like to estimate the full subset of the available movies that the customer would watch, given time. We&#8217;ll assign value <span class="math">\(y = 1\)</span> to such movies and <span class="math">\(y=0\)</span> to movies he wouldn&#8217;t watch. Notice that the generic logistic regression approach outlined above would return a default-positive result if applied to this problem: Assigning <span class="math">\(h = 1\)</span> to all of <span class="math">\(\textbf{F}\)</span> minimizes <span class="math">\(J\)</span>. This means that no information contained in <span class="math">\(\textbf{E}\)</span> is actually utilized in the logistic learning process &#8212; a counterintuitive choice for structured <span class="math">\(\textbf{E}\)</span> (e.g., the case where all movies watched thus far have been in a single category &#8212; martial arts films,&nbsp;say).</p>
<h2>Noisy&nbsp;labeling</h2>
<p>Some reasonable, alternative approaches do not return the default-positive response in the situation above. To see this, we first review here noisy labeling problems. Suppose we are given a training set with noisy labeling <span class="math">\(y^{\prime}\)</span>: Truly-positive examples <span class="math">\((y = 1)\)</span> are stochastically mislabeled in this set with frequency <span class="math">\(\alpha\)</span> as negative <span class="math">\((y^{\prime} = 0)\)</span>, and truly-negative examples <span class="math">\((y=0)\)</span> are mislabeled with frequency <span class="math">\(\beta\)</span> as positive <span class="math">\((y^{\prime} = 1)\)</span>. For hypothesis <span class="math">\(h\)</span>,&nbsp;let
</p>
<div class="math">\begin{eqnarray}\tag{3}
C(h) = Pr[h = 0 \vert y = 1]+ Pr[h = 1 \vert y= 0],
\end{eqnarray}</div>
<p>
the rate at which <span class="math">\(h\)</span> mislabels positive examples in the training set added to the rate at which it mislabels negative examples. Similarly, we define <span class="math">\(C^{\prime}(h)\)</span> as above, but with <span class="math">\(y\)</span> replaced by <span class="math">\(y^{\prime}\)</span>. Because <span class="math">\(y^{\prime}\)</span> is stochastic, we also average it in this case,&nbsp;giving
</p>
<div class="math">\begin{eqnarray}\tag{4}
C^{\prime}(h) = \left \langle Pr[h = 0 \vert y^{\prime} = 1]+ Pr[h = 1 \vert y^{\prime}= 0] \right \rangle_{y^{\prime}}.
\end{eqnarray}</div>
<p>
With these definitions, we have [see Blum and Michael (1998) or derive&nbsp;yourself] 
</p>
<div class="math">\begin{eqnarray}\tag{5}
C(h) \propto C^{\prime}(h),
\end{eqnarray}</div>
<p>
with <span class="math">\(\text{sign}(C) = \text{sign}(1 - \alpha - \beta) \times \text{sign}(C^{\prime})\)</span>. This result is very useful whenever we take <span class="math">\(C(h)\)</span> as our cost function<span class="math">\(^1\)</span>: Provided the total noise rate <span class="math">\(\alpha + \beta &lt;1\)</span>, it implies that we can find the &#8220;<span class="math">\(C\)</span>-optimizing&#8221; <span class="math">\(h\)</span> within any class of hypotheses by optimizing instead <span class="math">\(C^{\prime}\)</span> &#8212; a quantity that we can estimate given any particular noisy labeling realization <span class="math">\(y^{\prime}_0\)</span>&nbsp;as
</p>
<div class="math">\begin{eqnarray}\tag{6}
C^{\prime}(h) \approx \left (Pr[h = 0 \vert y^{\prime} = 1]+ Pr[h = 1 \vert y^{\prime}= 0] \right ) \vert_{y^{\prime} =y^{\prime}_0}.
\end{eqnarray}</div>
<h2>Application to no-negatives&nbsp;problem</h2>
<p>To make connection between the no-negatives and noisy-labeling problems, one can remodel the former as one where all unlabeled examples are considered to actually be negative examples (<span class="math">\(y^{\prime}_0 = 0\)</span>). This relabeling gives a correct label to all examples in the original training set <span class="math">\(\textbf{E}\)</span> (where <span class="math">\(y = y^{\prime}_0 = 1\)</span>) as well as to all truly-negative examples (where <span class="math">\(y = y^{\prime}_0 = 0\)</span>). However, all positive examples not in <span class="math">\(\textbf{E}\)</span> are now incorrectly labeled (they are assigned <span class="math">\(y^{\prime}_0 = 0\)</span>): This new labeling <span class="math">\(y^{\prime}_0\)</span> is noisy, with <span class="math">\(\alpha = Pr(y^{\prime}_0 =0 \vert y =1)\)</span> and <span class="math">\(\beta = Pr(y^{\prime}_0 =1 \vert y = 0 ) = 0\)</span>. We can now apply the Blum and Michael approach: We first approximate <span class="math">\(C^{\prime}\)</span> as above, making use of the particular noisy label we have access to. Second, we minimize the approximated <span class="math">\(C^{\prime}\)</span> over some class of hypotheses <span class="math">\(\{h\}\)</span>. This will in general return a non-uniform hypothesis (i.e., one that now makes use of the information contained in <span class="math">\(\textbf{E}\)</span>).</p>
<h2>Hybrid noisy-logistic approach of Lee and Liu (plus a&nbsp;tweak)</h2>
<p>The <span class="math">\(C \propto C^{\prime}\)</span> result is slick and provides a rigorous method for attacking the no-negatives problem. Unfortunately, <span class="math">\(C^{\prime}\)</span> is not convex, and as a consequence it can be difficult to minimize for large <span class="math">\(\vert \textbf{F} \vert\)</span> &#8212; in fact, its minimization is <span class="caps">NP</span>-hard. To mitigate this issue, Lee and Liu combine the noisy relabeling idea &#8212; now well-motivated by the Blum and Michael analysis &#8212; with logistic regression. They also suggest a particular re-weighting of the observed samples. However, we think that their particular choice of weighting is not very well-motivated, and we suggest here that one should instead pick an optimal weighting through consideration of a cross-validation set. With this approach, the method&nbsp;becomes:</p>
<p>​1) As above, assign examples in <span class="math">\(\textbf{E}\)</span> label <span class="math">\(y^{\prime} = 1\)</span> and examples in <span class="math">\(\textbf{F} - \textbf{E}\)</span> label <span class="math">\(y^{\prime} = 0\)</span>.<br>
2) Construct the weighted logistic cost&nbsp;function
</p>
<div class="math">\begin{eqnarray}\tag{7}
J(h; \rho) \equiv -\frac{1}{\vert \textbf{E} \vert}\sum_{i=1}^{\vert \textbf{E} \vert}  
\rho y^{\prime}_i \log(h_i) + (1-\rho) (1-y^{\prime}_i) \log(1- h_i) + \frac{\Lambda}{2}\sum_j T_j^2,
\end{eqnarray}</div>
<p>
with <span class="math">\(\rho \in [0,1]\)</span>, a re-weighting factor. (Lee and Liu suggest<span class="math">\(^2\)</span> using <span class="math">\(\rho = 1-\frac{\vert \textbf{E} \vert}{\vert \textbf{F} \vert}\)</span>).<br>
3) Minimize <span class="math">\(J\)</span>. By evaluating performance on a cross-validation set using your favorite criteria, optimize <span class="math">\(\rho\)</span> and <span class="math">\(\Lambda\)</span>.</p>
<h2>Toy&nbsp;example</h2>
<p>Here, we provide a toy system that allows for a sense of how the latter method discussed above works in practice. Given is a set of <span class="math">\(60\)</span> grid points in the plane, which can be added/subtracted individually to the positive training set (<span class="math">\(\textbf{E}\)</span>, green fill) by mouse click (a few are selected by default). The remaining points are considered to not be in the training set, but are relabeled as negative examples &#8212; this introduces noise, as described above. Clicking compute returns the <span class="math">\(h\)</span> values for each grid point, determined by minimizing the weighted cost function <span class="math">\(J\)</span> above: Here, we use the features <span class="math">\(\{1,x,y,x^2,xy,\)</span> <span class="math">\(y^2,x^3, x^2 y,\)</span> <span class="math">\(x y^2, y^3\}\)</span> to characterize each point. Those points with <span class="math">\(h\)</span> values larger than <span class="math">\(0.5\)</span> (i.e., those the hypothesis estimates as positive) are outlined in black. We have found that by carefully choosing the <span class="math">\(\rho\)</span> and <span class="math">\(\Lambda\)</span> values (often to be large and small, respectively), one can get a good fit to most training sets. By eye, the optimal weighting seems to often be close &#8212; but not necessarily equal to &#8212; the value suggested by Lee and&nbsp;Liu.</p>
<p><em>Fig. 1: Interactive weighted noisy-no-negatives solver. Click &#8220;compute&#8221; to run logistic regression.</em>
[<span class="caps">NOTE</span>:  new site does not yet support processing - I hope to reinsert the interactive object here as soon as&nbsp;possible].</p>
<h2>Discussion</h2>
<p>In this note, we have discussed methods for tackling classification sans negative examples &#8212; a problem that we found perplexing at first sight. It is interesting that standard logistic regression returns a default-positive result for such problems, while the two latter methods we discussed here are based on assuming that all points in <span class="math">\(\textbf{F} - \textbf{E}\)</span> are negatives. In fact, this assumption seems to be the essence of all the other methods referenced in Lee and Liu&#8217;s paper. Ultimately, these methods will only work if the training set provides a good sampling of the truly-positive space. If this is the case, then &#8220;defocusing&#8221; a bit, or blurring one&#8217;s eyes, will give a good sense of where the positive space sits. In the noisy-logistic approach, a good choice of <span class="math">\(\rho\)</span> and <span class="math">\(\Lambda\)</span> should effect a good result. Of course, when the training set does not sample the full positive space well, one can still use this approach to get a good approximation for the outline of the subspace&nbsp;sampled.</p>
<h2>Footnotes</h2>
<p><span class="math">\([1]\)</span>: The target function <span class="math">\(y\)</span> provides the unique minimum of <span class="math">\(C\)</span>. Therefore, choosing <span class="math">\(C\)</span> as our cost function and minimizing it over some class of hypotheses <span class="math">\(\{h\}\)</span> should return a reasonable estimate for <span class="math">\(y\)</span> (indeed, if <span class="math">\(y\)</span> is in the search class, we will find&nbsp;it).</p>
<p><span class="math">\([2]\)</span>: Lee and Liu justify their weighting suggestion on the basis that it means that a randomly selected positive example contributes with expected weight <span class="math">\(&gt;0.5\)</span> (see their paper). Yet, other weighting choices give even larger expected weights to the positive examples, so this is a poor justification. Nevertheless, their weighting choice does have the nice feature that the positive and negative spaces are effectively sampled with equal frequency. If optimizing over <span class="math">\(\rho\)</span> is too resource-costly for some application, using their weighting suggestion may be reasonable for this&nbsp;reason.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>


             
 
                <p id="post-share-links">
    Like this post?  Share on:
    <a href="https://twitter.com/intent/tweet?text=Machine%20Learning%20Methods%3A%20Classification%20without%20negative%C2%A0examples&url=https%3A//efavdb.com/methods-regression-without-negative-examples&hashtags=methods" target="_blank" rel="nofollow noopener noreferrer" title="Share on Twitter">Twitter</a>
    ❄
    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//efavdb.com/methods-regression-without-negative-examples" target="_blank" rel="nofollow noopener noreferrer" title="Share on Facebook">Facebook</a>
    ❄
    <a href="mailto:?subject=Machine%20Learning%20Methods%3A%20Classification%20without%20negative%C2%A0examples&amp;body=https%3A//efavdb.com/methods-regression-without-negative-examples" target="_blank" rel="nofollow noopener noreferrer" title="Share via Email">Email</a>
    </p>

                <hr />
    <div class="author_blurb">
        <a href="" target="_blank" rel="nofollow noopener noreferrer">
            <img src=/wp-content/uploads/2014/12/JonathanLinkedIn.jpg alt="Jonathan Landy Avatar" title="Jonathan Landy">
            <span class="author_name">Jonathan Landy</span>
        </a>
        Jonathan grew up in the midwest and then went to school at Caltech and UCLA. Following this, he did two postdocs, one at UCSB and one at UC Berkeley.  His academic research focused primarily on applications of statistical mechanics, but his professional passion has always been in the mastering, development, and practical application of slick math methods/tools. He worked as a data-scientist at Square for four years and is now working on a quantitative investing startup.
    </div>

            






<section>
    <h6 style="display:none;">Comments</h6>
    <p id="comment-message"> </p>

    <div class="accordion" id="accordion2">
        <div class="accordion-group">
            <div class="accordion-heading">
                <a class="accordion-toggle disqus-comment-count comment-count"
                   data-toggle="collapse"
                   data-parent="#accordion2"
                   data-disqus-identifier="https://efavdb.com/methods-regression-without-negative-examples"
                   href="https://efavdb.com/methods-regression-without-negative-examples#comment_thread"
                   id="comment-accordion-toggle">
                    Comments
                </a>
            </div>
            <div id="comment_thread" class="accordion-body collapse">
                <div class="accordion-inner">
                    <div class="comments">
                        <div id="disqus_thread"></div>
                        <script>
    var disqus_shortname = 'efavdb2';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());

    var disqus_identifier = 'https://efavdb.com/methods-regression-without-negative-examples';
    var disqus_url = 'https://efavdb.com/methods-regression-without-negative-examples';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>

<noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

            <hr/>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="previous-article">« <a href="https://efavdb.com/nba-week-6-predictions-week-7-predictions" title="Previous: NBA week 6 results, week 7 predictions, intro to dash">NBA week 6 results, week 7 predictions, intro to dash</a></li>
                <li class="next-article"><a href="https://efavdb.com/nba-week-7-results-week-8-predictions" title="Next: NBA week 7 results, week 8 predictions">NBA week 7 results, week 8 predictions</a> »</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2014-12-20T09:58:00-08:00">Dec 20, 2014</time>
            <h4>Category</h4>
            <a class="category-link" href="https://efavdb.com/categories#methods-theory-ref">Methods, Theory</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://efavdb.com/tags#methods-ref">methods
                    <span>8</span>
</a></li>
            </ul>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://twitter.com/efavdb" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="Twitter" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1da1f3"/><path fill="#fff" d="M437 152a72 72 0 0 1-40 12 72 72 0 0 0 32-40 72 72 0 0 1-45 17 72 72 0 0 0-122 65 200 200 0 0 1-145-74 72 72 0 0 0 22 94 72 72 0 0 1-32-7 72 72 0 0 0 56 69 72 72 0 0 1-32 1 72 72 0 0 0 67 50 200 200 0 0 1-105 29 200 200 0 0 0 309-179 200 200 0 0 0 35-37"/></svg>
    </a>
    <a href="https://github.com/efavdb" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
    <a href="https://www.youtube.com/channel/UClfvjoSiu0VvWOh5OpnuusA" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="YouTube" role="img" viewBox="0 0 512 512" fill="#ed1d24"><rect width="512" height="512" rx="15%"/><path d="m427 169c-4-15-17-27-32-31-34-9-239-10-278 0-15 4-28 16-32 31-9 38-10 135 0 174 4 15 17 27 32 31 36 10 241 10 278 0 15-4 28-16 32-31 9-36 9-137 0-174" fill="#fff"/><path d="m220 203v106l93-53"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
                        <button onclick="topFunction()" id="myBtn" title="Go to top">&#x25B2;</button>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>

    <div>
        <span class="site-name">EFAVDB</span> - Everybody's Favorite Data Blog
    </div>



    <!-- <div id="fpowered"> -->
    <!--     Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a> -->
    <!--     Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a> -->
    <!--      -->
    <!-- </div> -->
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>
        <script>
            //** Scroll to top button **
            //Get the button:
            mybutton = document.getElementById("myBtn");

            // When the user scrolls down 30px from the top of the document, show the button
            window.onscroll = function() {scrollFunction()};

            function scrollFunction() {
              if (document.body.scrollTop > 30 || document.documentElement.scrollTop > 30) {
                mybutton.style.display = "block";
              } else {
                mybutton.style.display = "none";
              }
            }

            // When the user clicks on the button, scroll to the top of the document
            function topFunction() {
              document.body.scrollTop = 0; // For Safari
              document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>