<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>GPU-accelerated Theano & Keras with Windows 10</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
<link href="./gpu-accelerated-theano-keras-with-windows-10.html" rel="canonical" />
  <!-- Feed -->

  <link href="./theme/css/style.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="./theme/css/code_blocks/github.css" rel="stylesheet">


  <!-- Custom fonts -->
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->



    <meta name="description" content="There are many tutorials with directions for how to use your Nvidia graphics card for GPU-accelerated Theano and Keras for Linux, but...">

    <meta name="author" content="Damien RJ">





<!-- Open Graph -->
<meta property="og:site_name" content="EFAVDB"/>
<meta property="og:title" content="GPU-accelerated Theano & Keras with Windows 10"/>
<meta property="og:description" content="There are many tutorials with directions for how to use your Nvidia graphics card for GPU-accelerated Theano and Keras for Linux, but..."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="./gpu-accelerated-theano-keras-with-windows-10.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2016-09-22 21:48:00-07:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="./author/damien-rj.html">
<meta property="article:section" content="Methods, Tools"/>
<meta property="og:image" content="./theme/images/post-bg.jpg">

<!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@efavdb">
    <meta name="twitter:title" content="GPU-accelerated Theano & Keras with Windows 10">
    <meta name="twitter:url" content="./gpu-accelerated-theano-keras-with-windows-10.html">

        <meta name="twitter:image:src" content="./theme/images/post-bg.jpg">

      <meta name="twitter:description" content="There are many tutorials with directions for how to use your Nvidia graphics card for GPU-accelerated Theano and Keras for Linux, but...">

<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "name": "GPU-accelerated Theano & Keras with Windows 10",
  "headline": "GPU-accelerated Theano & Keras with Windows 10",
  "datePublished": "2016-09-22 21:48:00-07:00",
  "dateModified": "",
  "author": {
    "@type": "Person",
    "name": "Damien RJ",
    "url": "./author/damien-rj.html"
  },
  "image": "./theme/images/post-bg.jpg",
  "url": "./gpu-accelerated-theano-keras-with-windows-10.html",
  "description": "There are many tutorials with directions for how to use your Nvidia graphics card for GPU-accelerated Theano and Keras for Linux, but..."
}
</script>
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>
          <li><a href="/" role="presentation">Home</a></li>
          <li><a href="/pages/about.html" role="presentation">About & Consulting</a></li>
          <li><a href="/archives.html" role="presentation">Archive</a></li>
          <li><a href="/tags.html" role="presentation">Tags</a></li>
          <li><a href="/pages/linselect.html" role="presentation">linselect - feature selection</a></li>


    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" >
      <div class="inner">
        <nav id="navigation">
            <span id="home-button" class="nav-button">
                <a class="home-button" href="./" title="Home"><i class="ic ic-arrow-left"></i> Home</a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">GPU-accelerated Theano & Keras with Windows 10</h1>
        <!-- TODO : Proper class for headline -->
        <span class="post-meta">
                <a href="./author/damien-rj.html">Damien Ramunno-Johnson</a>
            | <time datetime="Thu 22 September 2016">Thu 22 September 2016</time>
        </span>
        <!-- TODO : Modified check -->
      </div>
    </header>

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
                <p>There are many tutorials with directions for how to use your Nvidia graphics card for GPU-accelerated Theano and Keras for Linux, but there is only limited information out there for you if you want to set everything up with Windows and the current CUDA toolkit. This is a shame however because there are a large number of computers out there with very nice video cards that are only running windows, and it is not always practical to use a Virtual Machine, or Dual-Boot.  So for today's post we will go over how to get everything running in Windows 10 by saving you all the trial and error I went through. (All of these steps should also work in earlier versions of Windows).</p>
<h2>Dependencies</h2>
<p>Before getting started, make sure you have the following:</p>
<ul>
<li>NVIDIA card that supports CUDA (<a href="https://developer.nvidia.com/cuda-gpus">link</a>)</li>
<li>Python 2.7 (<a href="http://conda.pydata.org/miniconda.html">Anaconda</a> preferably)</li>
<li>Compilers for C/C++</li>
<li>CUDA 7.5</li>
<li>GCC for code generated by Theano</li>
</ul>
<h2>Setup</h2>
<h3>Visual Studio 2013 Community Edition Update 4</h3>
<p>First, go and download the installer for <a href="https://www.visualstudio.com/en-us/news/vs2013-community-vs.aspx">Visual Studio 2013 Community Edition Update 4</a>.  You can not use the 2015 version because it is still not supported by CUDA.  When installing, there is no need to install any of the optional packages.  When you are done add the compiler, <strong>C:\Program Files (x86)\Microsoft Visual Studio 12.0\VC\bin</strong>,  to your windows path.</p>
<p>To  add something to your windows path go to System, and then Advanced system settings.</p>
<p>System → Advanced system settings → Environment Variables → Path.</p>
<h3>CUDA</h3>
<p>Next, go the NVIDIA's website and <a href="https://developer.nvidia.com/cuda-downloads">download</a> the CUDA 7.5 toolkit. Select the right version for you computer. When you are installing it, make sure to pick custom install if you don't want your video card drivers to be overwritten with the version that comes with the toolkit, which are often out of date.  If it turns out that your version of the drivers are older than what comes with the toolkit,then there is no harm in updating your drivers, otherwise only pick the three boxes starting with CUDA.</p>
<h3>GCC</h3>
<p>The last thing we need to do  GCC compiler, I recommend <a href="http://tdm-gcc.tdragon.net/download">TDM-gcc</a>.  Install the 64 bit version, and then add the compiler to your windows path, the install has an option to do that for you automatically if you wish.</p>
<p>To make sure that everything is working at this point, run the the following command on the command line (cmd.exe) . If if finds the path for everything you are good to go.</p>
<p><code>where gcc where cl where nvcc where cudafe where cudafe++</code></p>
<h3>Theano and Keras</h3>
<p>At this point it is easy to install Theano and Keras, just you pip (or conda and pip)!</p>
<div class="highlight"><pre><span></span><span class="err">conda install mingw libpython  </span>
<span class="err">pip install theano  </span>
<span class="err">pip install keras</span>
</pre></div>


<p>After installing the python libraries you need to tell Theano to use the GPU instead of the CPU.  A lot of older posts would have you set this in the system environment, but it is possible to make a config file in your home directory named "<em>.theanorc.txt</em>" instead.  This also makes it easy to switch out config files.  Inside the file put the following:</p>
<div class="highlight"><pre><span></span><span class="k">[global]</span>
<span class="na">device</span> <span class="o">=</span> <span class="s">gpu</span>
<span class="na">floatX</span> <span class="o">=</span> <span class="s">float32</span>

<span class="k">[nvcc]</span>
<span class="na">compiler_bindir</span><span class="o">=</span><span class="s">C:\Program Files (x86)\Microsoft Visual Studio 12.0\VC\bin</span>
</pre></div>


<p>Lastly, set up the Keras config file <code>~/.keras/keras.json</code>.  If you haven't started Keras yet, the folder and file won't be there but you can create it. Inside the config put the following.</p>
<div class="highlight"><pre><span></span><span class="err">{</span>
<span class="err"> &quot;image_dim_ordering&quot;: &quot;tf&quot;,</span>
<span class="err"> &quot;epsilon&quot;: 1e-07,</span>
<span class="err"> &quot;floatx&quot;: &quot;float32&quot;, </span>
<span class="err"> &quot;backend&quot;: &quot;theano&quot;</span>
<span class="err">}</span>
</pre></div>


<h2>Testing Theano with GPU</h2>
<p>Using the following python code,  check if your installation of Theano is using your GPU.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">theano</span> <span class="kn">import</span> <span class="n">function</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">shared</span><span class="p">,</span> <span class="n">sandbox</span>  
<span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="k">as</span> <span class="nn">T</span>  
<span class="kn">import</span> <span class="nn">numpy</span>  
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">vlen</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">30</span> <span class="o">*</span> <span class="mi">768</span> <span class="c1"># 10 x #cores x # threads per core  </span>
<span class="n">iters</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">22</span><span class="p">)</span>  
<span class="n">x</span> <span class="o">=</span> <span class="n">shared</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="kp">asarray</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">vlen</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">floatX</span><span class="p">))</span>  
<span class="n">f</span> <span class="o">=</span> <span class="n">function</span><span class="p">([],</span> <span class="n">T</span><span class="o">.</span><span class="kp">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>  
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">maker</span><span class="o">.</span><span class="n">fgraph</span><span class="o">.</span><span class="n">toposort</span><span class="p">())</span>  
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>  
<span class="n">r</span> <span class="o">=</span> <span class="n">f</span><span class="p">()</span>  
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>  
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Looping </span><span class="si">%d</span><span class="s2"> times took </span><span class="si">%f</span><span class="s2"> seconds&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">iters</span><span class="p">,</span> <span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">))</span>  
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Result is </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">r</span><span class="p">,))</span>  
<span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="kp">any</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">op</span><span class="p">,</span> <span class="n">T</span><span class="o">.</span><span class="n">Elemwise</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">maker</span><span class="o">.</span><span class="n">fgraph</span><span class="o">.</span><span class="n">toposort</span><span class="p">()]):</span>  
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Used the cpu&#39;</span><span class="p">)</span>  
<span class="k">else</span><span class="p">:</span>  
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Used the gpu&#39;</span><span class="p">)</span>
</pre></div>


<h2>Testing Keras with GPU</h2>
<p>This code will make sure that everything is working and train a model on some random data. The first time might take a little longer because it the software needs to do some compiling.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>  
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span>

<span class="c1"># for a single-input model with 2 classes (binary):</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>  
<span class="n">model</span><span class="o">.</span><span class="kp">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>  
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;rmsprop&#39;</span><span class="p">,</span>  
<span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span>  
<span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<span class="c1"># generate dummy data  </span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>  
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">784</span><span class="p">))</span>  
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="kp">randint</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="kp">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># train the model, iterating on the data in batches  </span>
<span class="c1"># of 32 samples  </span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>  
</pre></div>


<p>If everything works you will see something like this!</p>
<p><a href="./wp-content/uploads/2016/09/output.png"><img alt="output" src="./wp-content/uploads/2016/09/output.png"></a></p>
<p>Now you can start playing with neural networks using your GPU!</p>
            </section>

            <section class="post-info">
                <div class="post-share">
                    <a class="twitter" href="https://twitter.com/share?text=GPU-accelerated Theano & Keras with Windows 10&amp;url=./gpu-accelerated-theano-keras-with-windows-10.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <i class="ic ic-twitter"></i><span class="hidden">Twitter</span>
                    </a>
                    <a class="facebook" href="https://www.facebook.com/sharer/sharer.php?u=./gpu-accelerated-theano-keras-with-windows-10.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <i class="ic ic-facebook"></i><span class="hidden">Facebook</span>
                    </a>
                    <a class="googleplus" href="https://plus.google.com/share?url=./gpu-accelerated-theano-keras-with-windows-10.html" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <i class="ic ic-googleplus"></i><span class="hidden">Google+</span>
                    </a>
                    <div class="clear"></div>
                </div>


                <div class="clear"></div>

                <aside class="post-author">


                        <figure class="post-author-avatar">
                            <img src=".//wp-content/uploads/2014/12/headshot.jpg" alt="Damien Ramunno-Johnson" />
                        </figure>
                    <div class="post-author-bio">
                        <h4 class="post-author-name"><a href="./author/damien-rj.html">Damien Ramunno-Johnson</a></h4>
                            <p class="post-author-about">Damien is a highly experienced researcher with a background in clinical and applied research. Like JSL, he got his PhD at UCLA. He has many years of experience working with imaging, and has a particularly strong background in image segmentation, registration, detection, data analysis, and more recently machine learning. He now works as a data-scientist at Square in San Francisco.</p>
                        <!-- Social linkes in alphabet order. -->
                    </div>
                    <div class="clear"></div>
                </aside>

                </section>


                <aside class="post-nav">
                    <a class="post-nav-next" href="./battleship.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-left"></i>
                                <h2 class="post-nav-title">Deep reinforcement learning, battleship</h2>
                            <p class="post-nav-excerpt">Here, we provide a brief introduction to reinforcement learning (RL) -- a general...</p>
                        </section>
                    </a>
                    <a class="post-nav-prev" href="./model-selection.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-right"></i>
                                <h2 class="post-nav-title">Hyperparameter sample-size dependence</h2>
                            <p class="post-nav-excerpt">Here, we briefly review a subtlety associated with machine-learning model selection:...</p>
                        </section>
                    </a>
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>

    <footer id="footer">
      <div class="inner">
        <section class="credits">
        </section>
      </div>
    </footer>
  </section>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script type="text/javascript" src="./theme/js/script.js"></script>

</body>
</html>