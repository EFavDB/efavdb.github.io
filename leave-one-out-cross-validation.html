<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Jonathan Landy" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Methods, Theory, " />

<meta property="og:title" content="Leave-one-out cross-validation "/>
<meta property="og:url" content="./leave-one-out-cross-validation.html" />
<meta property="og:description" content="This will be the first of a series of short posts relating to subject matter discussed in the text, “An Introduction to Statistical Learning”. This is an interesting read, but it often skips over statement proofs — that’s where this series of posts comes in! Here, I consider the content …" />
<meta property="og:site_name" content="EFAVDB" />
<meta property="og:article:author" content="Jonathan Landy" />
<meta property="og:article:published_time" content="2015-08-01T16:08:00-07:00" />
<meta name="twitter:title" content="Leave-one-out cross-validation ">
<meta name="twitter:description" content="This will be the first of a series of short posts relating to subject matter discussed in the text, “An Introduction to Statistical Learning”. This is an interesting read, but it often skips over statement proofs — that’s where this series of posts comes in! Here, I consider the content …">

        <title>Leave-one-out cross-validation  · EFAVDB
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Fira+Sans:300,400,700" rel="stylesheet" type='text/css' />
        <link href="https://fonts.googleapis.com/css?family=Cardo" rel="stylesheet" type='text/css' />        
        <link rel="stylesheet" type="text/css" href="./theme/css/elegant.prod.css" media="screen">
        <link rel="stylesheet" type="text/css" href="./theme/css/custom.css" media="screen">



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="./"><span class=site-name>EFAVDB</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       .
                                    >Home</a>
                                </li>
                                <li ><a href="./pages/authors.html">Authors</a></li>
                                <li ><a href="./categories.html">Categories</a></li>
                                <li ><a href="./tags.html">Tags</a></li>
                                <li ><a href="./archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="./search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="./leave-one-out-cross-validation.html">
                Leave-one-out&nbsp;cross-validation
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>This will be the first of a series of short posts relating to subject matter discussed in the text, <a href="http://www-bcf.usc.edu/~gareth/ISL/">&#8220;An Introduction to Statistical Learning&#8221;</a>. This is an interesting read, but it often skips over statement proofs &#8212; that&#8217;s where this series of posts comes in! Here, I consider the content of Section 5.1.2: This gives a lightning-quick &#8220;short cut&#8221; method for evaluating a regression&#8217;s leave-one-out cross-validation error. The method is applicable to any least-squares linear&nbsp;fit.</p>
<h3>Introduction: Leave-one-out&nbsp;cross-validation</h3>
<p>When carrying out a <a href="https://en.wikipedia.org/wiki/Regression_analysis">regression analysis</a>, one is often interested in two types of error measurement. The first is the training set error and the second is the generalization error. The former relates to how close the regression is to the data being fit. In contrast, the generalization error relates to how accurate the model will be when applied to other points. The latter is of particular interest whenever the regression will be used to make predictions on new&nbsp;points.</p>
<p><a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">Cross-validation</a> provides one method for estimating generalization errors. The approach centers around splitting the training data available into two sets, <em>a cross-validation training set</em> and <em>cross-validation test set</em>. The first of these is used for training a regression model. Its accuracy on the test set then provides a generalization error estimate. Here, we focus on a special form of cross-validation, called <em>leave-one-out cross-validation</em> (<span class="caps">LOOCV</span>). In this case, we pick only one point as the test set. We then build a model on all the remaining, complementary points, and evaluate its error on the single-point held out. A generalization error estimate is obtained by repeating this procedure for each of the training points available, averaging the&nbsp;results.</p>
<p><span class="caps">LOOCV</span> can be computationally expensive because it generally requires one to construct many models &#8212; equal in number to the size of the training set. However, for the special case of least-squares polynomial regression we have the following &#8220;short cut&#8221; identity:<br>
</p>
<div class="math">$$ \label{theorem} \tag{1}  
\sum_i \left ( \tilde{y}_i - y_i\right)^2 = \sum_i \left ( \frac{\hat{y}_i - y_i}{1 - h_i}\right)^2.  
$$</div>
<p><br>
Here, <span class="math">\(y_i\)</span> is the actual label value of training point <span class="math">\(i\)</span>, <span class="math">\(\tilde{y}_i\)</span> is the value predicted by the cross-validation model trained on all points except <span class="math">\(i\)</span>, <span class="math">\(\hat{y}_i\)</span> is the value predicted by the regression model trained on all points (including point <span class="math">\(i\)</span>), and <span class="math">\(h_i\)</span> is a function of the coordinate <span class="math">\(\vec{x}_i\)</span> &#8212; this is defined further below. Notice that the left side of (\ref{theorem}) is the <span class="caps">LOOCV</span> sum of squares error (the quantity we seek), while the right can be evaluated given only the model trained on the full data set. Fantastically, this allows us to evaluate the <span class="caps">LOOCV</span> error using only a single&nbsp;regression!</p>
<h3>Statement&nbsp;proof</h3>
<p>Consider the <span class="caps">LOOCV</span> step where we construct a model trained on all points except training example <span class="math">\(k\)</span>. Using a linear model of form <span class="math">\(\tilde{y}(\vec{x}) \equiv \vec{x}^T \cdot \vec{\beta}_k\)</span> &#8212; with <span class="math">\(\vec{\beta}_k\)</span> a coefficient vector &#8212; the sum of squares that must be minimized is<br>
</p>
<div class="math">$$\tag{2} \label{error_sum}  
J_k \equiv \sum_{i \not = k} \left ( \tilde{y}_i - y_i \right)^2 = \sum_{i \not = k} \left (\vec{x}^T_i \cdot \vec{\beta}_k - y_i \right)^2.  
$$</div>
<p><br>
Here, we&#8217;re using a subscript <span class="math">\(k\)</span> on <span class="math">\(\vec{\beta}_k\)</span> to highlight the fact that the above corresponds to the case where example <span class="math">\(k\)</span> is held out. We minimize (\ref{error_sum}) by taking the gradient with respect to <span class="math">\(\vec{\beta}_k\)</span>. Setting this to zero gives the equation<br>
</p>
<div class="math">$$\tag{3}  
\left( \sum_{i \not = k} \vec{x}_i \vec{x}_i^T \right) \cdot \vec{\beta}_k = \sum_{i \not = k} y_i \vec{x}_i.  
$$</div>
<p><br>
Similarly, the full model (trained on all points) coefficient vector <span class="math">\(\vec{\beta}\)</span> satisfies<br>
</p>
<div class="math">$$\tag{4} \label{full_con}  
\left( \sum_{i} \vec{x}_i \vec{x}_i^T \right) \cdot \vec{\beta} \equiv M \cdot \vec{\beta} = \sum_{i} y_i \vec{x}_i.  
$$</div>
<p><br>
Combining the prior two equations gives,<br>
</p>
<div class="math">$$\tag{5}  
\left (M - \vec{x}_k \vec{x}_k^T \right) \cdot \vec{\beta}_k = \left (\sum_{i} y_i \vec{x}_i\right) - y_k \vec{x}_k = M\cdot \vec{\beta} - y_k \vec{x}_k.  
$$</div>
<p><br>
Using the definition of <span class="math">\(\tilde{y}_k\)</span>, rearrangement of the above leads to the identity<br>
</p>
<div class="math">$$\tag{6}  
M \cdot \left ( \vec{\beta}_k - \vec{\beta} \right) = \left (\tilde{y}_k - y_k \right) \vec{x}_k.  
$$</div>
<p><br>
Left multiplication by <span class="math">\(\vec{x}_k^T M^{-1}\)</span> gives,<br>
</p>
<div class="math">$$\tag{7}  
\tilde{y}_k - \hat{y}_k = \left( \tilde{y}_k - y_k\right) - \left( \hat{y}_k - y_k \right) = \vec{x}_k^T M^{-1} \vec{x}_k \left (\tilde{y}_k - y_k \right).  
$$</div>
<p><br>
Finally, combining like-terms, squaring, and summing gives<br>
</p>
<div class="math">$$\tag{8}  
\sum_k \left (\tilde{y}_k - y_k \right) ^2 = \sum_k \left (\frac{\hat{y}_k - y_k}{1 -\vec{x}_k^T M^{-1} \vec{x}_k } \right)^2.  
$$</div>
<p><br>
This is (\ref{theorem}), where we now see the parameter <span class="math">\(h_k \equiv \vec{x}_k^T M^{-1} \vec{x}_k\)</span>. This is referred to as the &#8220;leverage&#8221; of <span class="math">\(\vec{x}_k\)</span> in the text. Notice also that <span class="math">\(M\)</span> is proportional to the correlation matrix of the <span class="math">\(\{\vec{x}_i\}\)</span>. <span class="math">\(\blacksquare\)</span></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>


             
 
            
                <hr />
    <div class="author_blurb">
        <a href="" target="_blank" rel="nofollow noopener noreferrer">
            <img src=/wp-content/uploads/2014/12/JonathanLinkedIn.jpg alt="Jonathan Landy Avatar" title="Jonathan Landy">
            <span class="author_name">Jonathan Landy</span>
        </a>
        Jonathan grew up in the midwest and then went to school at Caltech and UCLA. Following this, he did two postdocs, one at UCSB and one at UC Berkeley.  His academic research focused primarily on applications of statistical mechanics, but his professional passion has always been in the mastering, development, and practical application of slick math methods/tools. He worked as a data-scientist at Square for four years and is now working on a quantitative investing startup.
    </div>

            






            <hr/>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="previous-article">« <a href="./predicting-san-francisco-crimes.html" title="Previous: Machine learning to predict San Francisco crime">Machine learning to predict San Francisco crime</a></li>
                <li class="next-article"><a href="./build-a-web-scraper-lit-search.html" title="Next: Build a web scraper for a literature search - from soup to nuts">Build a web scraper for a literature search - from soup to nuts</a> »</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2015-08-01T16:08:00-07:00">Aug 1, 2015</time>
            <h4>Category</h4>
            <a class="category-link" href="./categories.html#methods-theory-ref">Methods, Theory</a>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://twitter.com/efavdb" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="Twitter" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1da1f3"/><path fill="#fff" d="M437 152a72 72 0 0 1-40 12 72 72 0 0 0 32-40 72 72 0 0 1-45 17 72 72 0 0 0-122 65 200 200 0 0 1-145-74 72 72 0 0 0 22 94 72 72 0 0 1-32-7 72 72 0 0 0 56 69 72 72 0 0 1-32 1 72 72 0 0 0 67 50 200 200 0 0 1-105 29 200 200 0 0 0 309-179 200 200 0 0 0 35-37"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>

    <div>
        <span class="site-name">EFAVDB</span> - Everybody's Favorite Data Blog
    </div>



    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>