<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Damien RJ" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Case studies, " />

<meta property="og:title" content="Forecasting Bike Sharing Demand "/>
<meta property="og:url" content="https://efavdb.com/bike-share-forecasting" />
<meta property="og:description" content="In today’s post, we document our efforts at applying a gradient boosted trees model to forecast bike sharing demand — a problem posed in a recent Kagglecompetition. For those not familiar, Kaggle is a site where one can compete with other data scientists on various data challenges. Top scorers …" />
<meta property="og:site_name" content="EFAVDB" />
<meta property="og:article:author" content="Damien RJ" />
<meta property="og:article:published_time" content="2015-03-26T09:20:00-07:00" />
<meta name="twitter:title" content="Forecasting Bike Sharing Demand ">
<meta name="twitter:description" content="In today’s post, we document our efforts at applying a gradient boosted trees model to forecast bike sharing demand — a problem posed in a recent Kagglecompetition. For those not familiar, Kaggle is a site where one can compete with other data scientists on various data challenges. Top scorers …">

        <title>Forecasting Bike Sharing Demand  · EFAVDB
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="https://fonts.googleapis.com/css?family=Fira+Sans:300,400,700" rel="stylesheet" type='text/css' />
        <link href="https://fonts.googleapis.com/css?family=Cardo:400,700" rel="stylesheet" type='text/css' />        
        <link rel="stylesheet" type="text/css" href="https://efavdb.com/theme/css/elegant.prod.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://efavdb.com/theme/css/custom.css" media="screen">

        <link href="https://efavdb.com/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="EFAVDB - Full Atom Feed" />
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
     (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
     m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
     })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-57405119-1', 'auto');
    ga('send', 'pageview');
</script>


    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://efavdb.com/"><span class=site-name>EFAVDB</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://efavdb.com
                                    >Home</a>
                                </li>
                                <li ><a href="https://efavdb.com/pages/authors.html">Authors</a></li>
                                <li ><a href="https://efavdb.com/categories.html">Categories</a></li>
                                <li ><a href="https://efavdb.com/tags.html">Tags</a></li>
                                <li ><a href="https://efavdb.com/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://efavdb.com/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span8 offset2">
        <h1>
            <a href="https://efavdb.com/bike-share-forecasting">
                Forecasting Bike Sharing&nbsp;Demand
            </a>
        </h1>
    </header>
    <div class="span2"></div>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>In today&#8217;s post, we document our efforts at applying a gradient boosted trees model to forecast bike sharing demand &#8212; a problem posed in a recent <a href="https://www.kaggle.com/c/bike-sharing-demand">Kaggle</a>competition. For those not familiar, Kaggle is a site where one can compete with other data scientists on various data challenges. Top scorers often win prize money, but the site more generally serves as a great place to grab interesting datasets to explore and play with. With the simple optimization steps discussed below, we managed to quickly move from the bottom 10% of the competition &#8212; our first-pass attempt&#8217;s score &#8212; to the top 10%: no&nbsp;sweat!</p>
<p>Our work here was inspired by a <a href="http://blog.dato.com/using-gradient-boosted-trees-to-predict-bike-sharing-demand">post</a> by the people at <a href="http://blog.dato.com/">Dato.com</a>, who used the bike sharing competition as an opportunity to demonstrate their software. Here, we go through a similar, but more detailed discussion using the python package <a href="http://scikit-learn.org/stable/">SKlearn</a>.</p>
<h2>Introduction</h2>
<p>Bike sharing systems are gaining popularity around the world &#8212; there are over 500 different programs currently operating in various cities, and counting!  These programs are generally funded through rider membership fees, or through pay-to-ride one time rental fees. Key to the convenience of these programs is the fact that riders who pick up a bicycle from one station can return the bicycle to any other in the network.  These systems generate a great deal of data relating to various ride details, including travel time, departure location, arrival location, and so on.  This data has the potential to be very useful for studying city mobility. The data we look at today comes from Washington D. C.&#8217;s <a href="https://www.capitalbikeshare.com/">Capital Bikeshare</a> program. The goal of the Kaggle competition is to leverage the historical data provided in order to forecast future bike rental demand within the&nbsp;city.</p>
<p>As we detailed in an earlier <a href="http://efavdb.github.io/notes-on-trees">post</a>, boosting provides a general method for increasing a machine learning algorithm&#8217;s performance. Here, in order to model the Capital Bikeshare program&#8217;s demand curves, we&#8217;ll be applying a gradient boosted trees model (<span class="caps">GBM</span>).  Simply put, <span class="caps">GBM</span>&#8217;s are constructed by iteratively fitting a series of simple trees to a training set, where each new tree attempts to fit the residuals, or errors, of the trees that came before it. With the addition of each new tree the training error is further reduced, typically asymptoting to a reasonably accurate model &#8212; but one must watch out for overfitting &#8212; see&nbsp;below!</p>
<h2><strong>Loading package and&nbsp;data</strong></h2>
<p>Below, we show the relevant commands needed to load all the packages and training/test data we will be using. We work with the package <a href="http://pandas.pydata.org/">Pandas</a>, whose DataFrame data structure enables quick and easy data loading and wrangling. We take advantage of this package immediately below, where in the last lines we use its parse_dates method to convert the first column of our provided data &#8212; which can be downloaded <a href="https://www.kaggle.com/c/bike-sharing-demand">here</a> &#8212; from string to datetime&nbsp;format.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">ensemble</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.grid_search</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>

<span class="c1">#Load Data with pandas, and parse the</span>
<span class="c1">#first column into datetime</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;train.csv&#39;</span><span class="p">,</span> <span class="n">parse_dates</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="kp">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;test.csv&#39;</span><span class="p">,</span> <span class="n">parse_dates</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>


<p>The training data provided contains the following&nbsp;fields:</p>
<p><strong><em>datetime</em></strong> - hourly date + timestamp
<strong><em>season</em></strong> -  1 = spring, 2 = summer, 3 = fall, 4 = winter
<strong><em>holiday</em></strong> - whether the day is considered a holiday
<strong><em>workingday</em></strong> - whether the day is neither a weekend nor holiday
<strong><em>weather</em></strong>:</p>
<ol>
<li>Clear, Few clouds, Partly cloudy, Partly&nbsp;cloudy</li>
<li>Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds,&nbsp;Mist</li>
<li>Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered&nbsp;clouds</li>
<li>Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow +&nbsp;Fog</li>
</ol>
<p><strong><em>temp</em></strong> - temperature in Celsius
<strong><em>atemp</em></strong> - &#8220;feels like&#8221; temperature in Celsius
<strong><em>humidity</em></strong> - relative humidity
<strong><em>windspeed</em></strong> - wind speed
<strong><em>casual</em></strong> - number of non-registered user rentals initiated
<strong><em>registered</em></strong> - number of registered user rentals initiated
<strong><em>count</em></strong> - number of total&nbsp;rentals</p>
<p>The data provided spans two years. The training set contains the first 19 days of each month considered, while the test set data corresponds to the remaining days in each&nbsp;month.</p>
<p>Looking ahead, we anticipate that the year, month, day of week, and hour will serve as important features for characterizing the bike demand at any given moment.  These features are easily extracted from the datetime formatted-values loaded above. In the following lines, we add these features to our&nbsp;DataFrames.</p>
<div class="highlight"><pre><span></span><span class="o">#</span><span class="n">Feature</span> <span class="n">engineering</span>
<span class="n">temp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DatetimeIndex</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;datetime&#39;</span><span class="p">])</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="p">.</span><span class="k">year</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;month&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="p">.</span><span class="k">month</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;hour&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="p">.</span><span class="n">hour</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;weekday&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="p">.</span><span class="n">weekday</span>

<span class="n">temp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DatetimeIndex</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;datetime&#39;</span><span class="p">])</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;year&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="p">.</span><span class="k">year</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;month&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="p">.</span><span class="k">month</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;hour&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="p">.</span><span class="n">hour</span>
<span class="n">test</span><span class="p">[</span><span class="s1">&#39;weekday&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="p">.</span><span class="n">weekday</span>

<span class="o">#</span><span class="n">Define</span> <span class="n">features</span> <span class="n">vector</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;season&#39;</span><span class="p">,</span> <span class="s1">&#39;holiday&#39;</span><span class="p">,</span> <span class="s1">&#39;workingday&#39;</span><span class="p">,</span> <span class="s1">&#39;weather&#39;</span><span class="p">,</span>
<span class="s1">&#39;temp&#39;</span><span class="p">,</span> <span class="s1">&#39;atemp&#39;</span><span class="p">,</span> <span class="s1">&#39;humidity&#39;</span><span class="p">,</span> <span class="s1">&#39;windspeed&#39;</span><span class="p">,</span> <span class="s1">&#39;year&#39;</span><span class="p">,</span>
<span class="s1">&#39;month&#39;</span><span class="p">,</span> <span class="s1">&#39;weekday&#39;</span><span class="p">,</span> <span class="s1">&#39;hour&#39;</span><span class="p">]</span>
</pre></div>


<h2><strong>Evaluation&nbsp;metric</strong></h2>
<p>The evaluation metric that Kaggle uses to rank competing algorithms is the Root Mean Squared Logarithmic Error (<span class="caps">RMSLE</span>).</p>
<div class="math">\begin{eqnarray}
J = \sqrt{\frac{1}{n} \sum_{i=1}^n [\ln(p_i + 1) - \ln(a_i+1)]^2 }
\end{eqnarray}</div>
<p>
Here,</p>
<ul>
<li><span class="math">\(n\)</span> is the number of hours in the test&nbsp;set</li>
<li><span class="math">\(p_i\)</span> is the predicted number of bikes rented in a given&nbsp;hour</li>
<li><span class="math">\(a_i\)</span> is the actual rent&nbsp;count</li>
<li><span class="math">\(ln(x)\)</span> is the natural&nbsp;logarithm</li>
</ul>
<p>With ranking determined as above, our aim becomes to accurately guess the natural logarithm of bike demand at different times (actually demand count plus one, in order to avoid infinities associated with times where demand is nil). To facilitate this, we add the logarithm of the casual, registered, and total counts to our training DataFrame&nbsp;below.</p>
<div class="highlight"><pre><span></span><span class="c1">#the evaluation metric is the RMSE in the log domain,</span>
<span class="c1">#so we should transform the target columns into log domain as well.</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;casual&#39;</span><span class="p">,</span> <span class="s1">&#39;registered&#39;</span><span class="p">,</span> <span class="s1">&#39;count&#39;</span><span class="p">]:</span>
  <span class="n">train</span><span class="p">[</span><span class="s1">&#39;log-&#39;</span> <span class="o">+</span> <span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>


<p>Notice that in the code above we use the <span class="math">\(log1p()\)</span> function instead of the more familiar <span class="math">\(log(1+x)\)</span>. For large values of <span class="math">\(x\)</span>, these two functions are actually equivalent. However, at very small values of <span class="math">\(x\)</span>, the two can disagree. The source of the discrepancy is floating point error: For very small <span class="math">\(x\)</span>, python will send <span class="math">\(1+x \to 1\)</span>, which when supplied as an argument to <span class="math">\(log(1+x)\)</span> will return <span class="math">\(log(1)=0\)</span>. The function <span class="math">\(log1p(x) \sim x\)</span> in this limit. The difference is not very important when the result is being added to other numbers, but can be very important in a multiplicative operation. We use this function instead for this reason. The inverse of <span class="math">\(log(x+1)\)</span> is <span class="math">\(e^{x} -1\)</span> &#8212; an operation we will also need to make use of later, in order to return linear-scale demand values. We&#8217;ll use an analog of the <span class="math">\(log1p()\)</span> function, numpy&#8217;s <span class="math">\(expm1()\)</span> function, to carry out this&nbsp;inversion.</p>
<h2><strong>Model&nbsp;development</strong></h2>
<h4><strong>A first&nbsp;pass</strong></h4>
<p>The Gradient Boosting Machine (<span class="caps">GBM</span>) we will be using has some associated hyperparameters that will eventually need to be optimized. These&nbsp;include:</p>
<ul>
<li>n_estimators = the number of boosting stages, or trees, to&nbsp;use.</li>
<li>max_depth = maximum depth of the individual regression&nbsp;trees.</li>
<li>learning_rate = shrinks the contribution of each tree by the learning&nbsp;rate.</li>
<li>in_samples_leaf = the minimum number of samples required to be at a leaf&nbsp;node</li>
</ul>
<p>However, in order to get our feet wet, we&#8217;ll begin by just picking some ad hoc values for these parameters. The code below fits a <span class="caps">GBM</span> to the log-demand training data, and then converts predicted log-demand into the competition&#8217;s required format &#8212; in particular, the demand is output in linear&nbsp;scale.</p>
<div class="highlight"><pre><span></span><span class="n">clf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ensemble</span><span class="p">.</span><span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="w"></span>
<span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span><span class="w"> </span><span class="n">max_depth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="w"></span>
<span class="n">clf</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="o">[</span><span class="n">features</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">train</span><span class="o">[</span><span class="n">&#39;log-count&#39;</span><span class="o">]</span><span class="p">)</span><span class="w"></span>
<span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">clf</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="o">[</span><span class="n">features</span><span class="o">]</span><span class="p">)</span><span class="w"></span>
<span class="k">result</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="n">expm1</span><span class="p">(</span><span class="k">result</span><span class="p">)</span><span class="w"></span>

<span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="err">{</span><span class="s1">&#39;datetime&#39;</span><span class="err">:</span><span class="n">test</span><span class="o">[</span><span class="n">&#39;datetime&#39;</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;count&#39;</span><span class="err">:</span><span class="k">result</span><span class="err">}</span><span class="p">)</span><span class="w"></span>
<span class="n">df</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;results1.csv&#39;</span><span class="p">,</span><span class="w"> </span><span class="k">index</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">False</span><span class="p">,</span><span class="w"> </span><span class="n">columns</span><span class="o">=[</span><span class="n">&#39;datetime&#39;,&#39;count&#39;</span><span class="o">]</span><span class="p">)</span><span class="w"></span>
</pre></div>


<p>In the last lines above, we have used the DataFrames to_csv() method in order to output results for competition submission. Example output is shown below. Without a hitch, we successfully submitted the results of this preliminary analysis to Kaggle. The only bad news was that our model scored in the bottom 10%. Fortunately, some simple optimizations that follow led to significant improvements in our&nbsp;standing.</p>
<table>
<thead>
<tr>
<th>datetime</th>
<th>count</th>
</tr>
</thead>
<tbody>
<tr>
<td>2011-01-20 0:00:00</td>
<td>0</td>
</tr>
<tr>
<td>2011-01-20 0:01:00</td>
<td>0</td>
</tr>
<tr>
<td>2011-01-20 0:02:00</td>
<td>0</td>
</tr>
</tbody>
</table>
<h4><strong>Hyperparameter&nbsp;tuning</strong></h4>
<p>We now turn to the challenge of tuning our <span class="caps">GBM</span>&#8217;s hyperparameters. In order to carry this out, we segmented our training data into a training set and a validation set. The validation set allowed us to check the accuracy of our model locally, without having to submit to Kaggle. This also helped us to avoid overfitting&nbsp;issues.</p>
<p>As mentioned earlier, the training data provided covers the first 19 days of each month. In segmenting this data, we opted to use days 17-19 for validation. We then used this validation set to optimize the model&#8217;s hyperparameters. As a first-pass at this, we again chose an ad hoc value for n_estimators, but optimized over the remaining degrees of freedom. The code follows, where we make use of GridSearchCV() to perform our parameter&nbsp;sweep.</p>
<div class="highlight"><pre><span></span><span class="c1">#Split data into training and validation sets</span>
<span class="n">temp</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DatetimeIndex</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;datetime&#39;</span><span class="p">])</span>
<span class="n">training</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">temp</span><span class="o">.</span><span class="n">day</span> <span class="o">&lt;=</span> <span class="mi">16</span><span class="p">]</span>
<span class="n">validation</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">temp</span><span class="o">.</span><span class="n">day</span> <span class="o">&gt;</span> <span class="mi">16</span><span class="p">]</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">],</span>
              <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
              <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">est</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="c1"># this may take awhile</span>
<span class="n">gs_cv</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span>
<span class="n">est</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
<span class="n">training</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">training</span><span class="p">[</span><span class="s1">&#39;log-count&#39;</span><span class="p">])</span>

<span class="c1"># best hyperparameter setting</span>
<span class="n">gs_cv</span><span class="o">.</span><span class="n">best_params_</span>

<span class="c1">#Baseline error</span>
<span class="n">error_count</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">validation</span><span class="p">[</span><span class="s1">&#39;log-count&#39;</span><span class="p">],</span> <span class="n">gs_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">validation</span><span class="p">[</span><span class="n">features</span><span class="p">]))</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">gs_cv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;datetime&#39;</span><span class="p">:</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;datetime&#39;</span><span class="p">],</span> <span class="s1">&#39;count&#39;</span><span class="p">:</span><span class="n">result</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;results2.csv&#39;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;datetime&#39;</span><span class="p">,</span><span class="s1">&#39;count&#39;</span><span class="p">])</span>
</pre></div>


<ul>
<li>Note: If you want to run n_jobs &gt; 1 on a Windows machine, the script needs to be in an &#8220;if <strong>name</strong> == &#8216;<strong>main</strong>&#8216;:&#8221; block. Otherwise the script will&nbsp;fail.</li>
</ul>
<table>
<thead>
<tr>
<th>day</th>
<th>Best Parms</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>learning_rate</td>
</tr>
<tr>
<td>2</td>
<td>max_depth</td>
</tr>
<tr>
<td>2</td>
<td>min_samples_leaf</td>
</tr>
</tbody>
</table>
<p>The optimized parameters are shown above. Submitting the resulting model to Kaggle, we found that we had moved from the bottom 10% of models to the top 20%!  An awesome improvement, but we still have one final hyperparameter to&nbsp;optimize.</p>
<h4><strong>Tuning the number of&nbsp;estimators</strong></h4>
<p>In boosted models, training set performance will always improve as the number of estimators is increased. However, at large estimator number, overfitting can start to become an issue. Learning curves provide a method for optimization. These are constructed by plotting the error on both the training and validation sets as a function of the number of estimators used. The code below generates such a curve for our&nbsp;model.</p>
<div class="highlight"><pre><span></span><span class="n">error_train</span><span class="o">=</span><span class="p">[]</span>
<span class="n">error_validation</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">501</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
  <span class="n">clf</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">GradientBoostingRegressor</span><span class="p">(</span>
  <span class="n">n_estimators</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
  <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>

  <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">training</span><span class="p">[</span><span class="s1">&#39;log-count&#39;</span><span class="p">])</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">training</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
  <span class="n">error_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
  <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">training</span><span class="p">[</span><span class="s1">&#39;log-count&#39;</span><span class="p">]))</span>

  <span class="n">result</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">validation</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
  <span class="n">error_validation</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
  <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">validation</span><span class="p">[</span><span class="s1">&#39;log-count&#39;</span><span class="p">]))</span>

<span class="c1">#Plot the data</span>
<span class="n">x</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">501</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;ggplot&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">error_train</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">error_validation</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Number of Estimators&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Error&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Train&#39;</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Error vs. Number of Estimators&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>


<p><img alt="Error vs Number of Estimators" src="https://efavdb.com/wp-content/uploads/2015/03/figure_1-e1427234375629.png"></p>
<p>Notice in the plot that by the time the number estimators in our <span class="caps">GBM</span> reaches about 80, the error of our model as applied to the validation set starts to slowly increase, though the error on the training set continues to decrease steadily. The diagnosis is that the model begins to overfit at this point. Moving forward, we will set n_estimators to 80, rather than 500, the value we were using above. Reducing the number of estimators reduced the calculated error and moved us to a higher position on the&nbsp;leaderboard.</p>
<h2><strong>Separate models for registered and casual&nbsp;users</strong></h2>
<p>Reviewing the data, we see that we have info regarding two types of riders: casual and registered riders. It is plausible that each group&#8217;s behavior differs, and that we might be able to improve our performance by modeling each separately. Below, we carry this out, and then also merge the two group&#8217;s predicted values to obtain a net predicted demand. We also repeat the hyperparameter sweep steps covered above &#8212; this returned similar values. Resubmitting the resulting model, we found we had increased our standing in the competition by a few&nbsp;percent.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">merge_predict</span><span class="p">(</span><span class="n">model1</span><span class="p">,</span> <span class="n">model2</span><span class="p">,</span> <span class="n">test_data</span><span class="p">):</span>
  <span class="c1"># Combine the predictions of two separately trained models.</span>
  <span class="c1"># The input models are in the log domain and returns the predictions</span>
  <span class="c1"># in original domain.</span>
  <span class="n">p1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">model1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">))</span>
  <span class="n">p2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expm1</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_data</span><span class="p">))</span>
  <span class="n">p_total</span> <span class="o">=</span> <span class="p">(</span><span class="n">p1</span><span class="o">+</span><span class="n">p2</span><span class="p">)</span>
  <span class="k">return</span><span class="p">(</span><span class="n">p_total</span><span class="p">)</span>
<span class="n">est_casual</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span><span class="p">)</span>
<span class="n">est_registered</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">GradientBoostingRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span><span class="p">)</span>
<span class="n">param_grid2</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
               <span class="s1">&#39;_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">],</span>
<span class="p">}</span>

<span class="n">gs_casual</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">est_casual</span><span class="p">,</span> <span class="n">param_grid2</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">training</span><span class="p">[</span><span class="s1">&#39;log-casual&#39;</span><span class="p">])</span>
<span class="n">gs_registered</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">est_registered</span><span class="p">,</span> <span class="n">param_grid2</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">[</span><span class="n">features</span><span class="p">],</span> <span class="n">training</span><span class="p">[</span><span class="s1">&#39;log-registered&#39;</span><span class="p">])</span>

<span class="n">result3</span> <span class="o">=</span> <span class="n">merge_predict</span><span class="p">(</span><span class="n">gs_casual</span><span class="p">,</span> <span class="n">gs_registered</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;datetime&#39;</span><span class="p">:</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;datetime&#39;</span><span class="p">],</span> <span class="s1">&#39;count&#39;</span><span class="p">:</span><span class="n">result3</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;results3.csv&#39;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;datetime&#39;</span><span class="p">,</span><span class="s1">&#39;count&#39;</span><span class="p">])</span>
</pre></div>


<p>The last step is to submit a final set of model predictions, this time training on the full labeled dataset provided. With these simple steps, we ended up in the top 11% on the competition&#8217;s leaderboard with a rank of&nbsp;280/2467!</p>
<p><a href="https://efavdb.com/wp-content/uploads/2015/03/score.png"><img alt="score" src="https://efavdb.com/wp-content/uploads/2015/03/score.png"></a></p>
<div class="highlight"><pre><span></span><span class="o">&lt;</span><span class="n">pre</span><span class="o">&gt;</span>
<span class="n">est_casual</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">GradientBoostingRegressor</span><span class="p">(</span>
<span class="n">n_estimators</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span><span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">est_registered</span> <span class="o">=</span> <span class="n">ensemble</span><span class="o">.</span><span class="n">GradientBoostingRegressor</span><span class="p">(</span>
<span class="n">n_estimators</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span><span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>

<span class="n">est_casual</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;log-casual&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">est_registered</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">features</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;log-registered&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">result4</span> <span class="o">=</span> <span class="n">merge_predict</span><span class="p">(</span><span class="n">est_casual</span><span class="p">,</span> <span class="n">est_registered</span><span class="p">,</span> <span class="n">test</span><span class="p">[</span><span class="n">features</span><span class="p">])</span>

<span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;datetime&#39;</span><span class="p">:</span><span class="n">test</span><span class="p">[</span><span class="s1">&#39;datetime&#39;</span><span class="p">],</span> <span class="s1">&#39;count&#39;</span><span class="p">:</span><span class="n">result4</span><span class="p">})</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;results4.csv&#39;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;datetime&#39;</span><span class="p">,</span><span class="s1">&#39;count&#39;</span><span class="p">])</span>
</pre></div>


<p><strong><span class="caps">DISCUSSION</span></strong></p>
<p>By iteratively tuning a <span class="caps">GBM</span>, we were able to quickly climb the leaderboard for this particular Kaggle competition. With further feature extraction work, we believe further improvements could readily be made. However, our goal here was only to practice our rapid development skills, so we won&#8217;t be spending much time on further fine-tuning. At any rate, our results have convinced us that simple boosted models can often provide excellent&nbsp;results.</p>
<p><a href="https://github.com/EFavDB/bike-forecast" title="GitHub Repo"><img alt="Open GitHub Repo" src="https://efavdb.com/wp-content/uploads/2015/03/GitHub_Logo.png"></a>
Open GitHub&nbsp;Repo</p>
<p>Note: With this post, we have begun to post our python scripts and data at GitHub. Clicking on the icon at left will take you to our repository. Feel free to stop by and take a&nbsp;look!</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>


             
 
                <p id="post-share-links">
    Like this post?  Share on:
    <a href="https://twitter.com/intent/tweet?text=Forecasting%20Bike%20Sharing%C2%A0Demand&url=https%3A//efavdb.com/bike-share-forecasting" target="_blank" rel="nofollow noopener noreferrer" title="Share on Twitter">Twitter</a>
    ❄
    <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//efavdb.com/bike-share-forecasting" target="_blank" rel="nofollow noopener noreferrer" title="Share on Facebook">Facebook</a>
    ❄
    <a href="mailto:?subject=Forecasting%20Bike%20Sharing%C2%A0Demand&amp;body=https%3A//efavdb.com/bike-share-forecasting" target="_blank" rel="nofollow noopener noreferrer" title="Share via Email">Email</a>
    </p>

                <hr />
    <div class="author_blurb">
        <a href="" target="_blank" rel="nofollow noopener noreferrer">
            <img src=/wp-content/uploads/2014/12/headshot.jpg alt="Damien RJ Avatar" title="Damien RJ">
            <span class="author_name">Damien RJ</span>
        </a>
        Damien is a highly experienced researcher with a background in clinical and applied research. Like JSL, he got his PhD at UCLA. He has many years of experience working with imaging, and has a particularly strong background in image segmentation, registration, detection, data analysis, and more recently machine learning. He now works as a data-scientist at Square in San Francisco.
    </div>

            






<section>
    <h6 style="display:none;">Comments</h6>
    <p id="comment-message"> </p>

    <div class="accordion" id="accordion2">
        <div class="accordion-group">
            <div class="accordion-heading">
                <a class="accordion-toggle disqus-comment-count comment-count"
                   data-toggle="collapse"
                   data-parent="#accordion2"
                   data-disqus-identifier="https://efavdb.com/bike-share-forecasting"
                   href="https://efavdb.com/bike-share-forecasting#comment_thread"
                   id="comment-accordion-toggle">
                    Comments
                </a>
            </div>
            <div id="comment_thread" class="accordion-body collapse">
                <div class="accordion-inner">
                    <div class="comments">
                        <div id="disqus_thread"></div>
                        <script>
    var disqus_shortname = 'efavdb2';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = '//' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());

    var disqus_identifier = 'https://efavdb.com/bike-share-forecasting';
    var disqus_url = 'https://efavdb.com/bike-share-forecasting';

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>

<noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

            <hr/>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="previous-article">« <a href="https://efavdb.com/nba-week-18-summary-week-19-predictions" title="Previous: NBA week 18 summary, week 19 predictions">NBA week 18 summary, week 19 predictions</a></li>
                <li class="next-article"><a href="https://efavdb.com/nba-week-19-summary-week-20-predictions" title="Next: NBA week 19 summary, week 20 predictions">NBA week 19 summary, week 20 predictions</a> »</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2015-03-26T09:20:00-07:00">Mar 26, 2015</time>
            <h4>Category</h4>
            <a class="category-link" href="https://efavdb.com/categories.html#case-studies-ref">Case studies</a>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://twitter.com/efavdb" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="Twitter" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1da1f3"/><path fill="#fff" d="M437 152a72 72 0 0 1-40 12 72 72 0 0 0 32-40 72 72 0 0 1-45 17 72 72 0 0 0-122 65 200 200 0 0 1-145-74 72 72 0 0 0 22 94 72 72 0 0 1-32-7 72 72 0 0 0 56 69 72 72 0 0 1-32 1 72 72 0 0 0 67 50 200 200 0 0 1-105 29 200 200 0 0 0 309-179 200 200 0 0 0 35-37"/></svg>
    </a>
    <a href="https://github.com/efavdb" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
    <a href="https://www.youtube.com/channel/UClfvjoSiu0VvWOh5OpnuusA" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="YouTube" role="img" viewBox="0 0 512 512" fill="#ed1d24"><rect width="512" height="512" rx="15%"/><path d="m427 169c-4-15-17-27-32-31-34-9-239-10-278 0-15 4-28 16-32 31-9 38-10 135 0 174 4 15 17 27 32 31 36 10 241 10 278 0 15-4 28-16 32-31 9-36 9-137 0-174" fill="#fff"/><path d="m220 203v106l93-53"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
                        <button onclick="topFunction()" id="myBtn" title="Go to top">&#x25B2;</button>
                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>

    <div>
        <span class="site-name">EFAVDB</span> - Everybody's Favorite Data Blog
    </div>



    <!-- <div id="fpowered"> -->
    <!--     Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a> -->
    <!--     Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a> -->
    <!--      -->
    <!-- </div> -->
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>
        <script>
            //** Scroll to top button **
            //Get the button:
            mybutton = document.getElementById("myBtn");

            // When the user scrolls down 30px from the top of the document, show the button
            window.onscroll = function() {scrollFunction()};

            function scrollFunction() {
              if (document.body.scrollTop > 30 || document.documentElement.scrollTop > 30) {
                mybutton.style.display = "block";
              } else {
                mybutton.style.display = "none";
              }
            }

            // When the user clicks on the button, scroll to the top of the document
            function topFunction() {
              document.body.scrollTop = 0; // For Safari
              document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>