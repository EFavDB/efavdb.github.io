<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>Stochastic geometric series</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
<link href="./stochastic-geometric-series.html" rel="canonical" />
  <!-- Feed -->

  <link href="./theme/css/style.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="./theme/css/code_blocks/github.css" rel="stylesheet">


  <!-- Custom fonts -->
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->



    <meta name="description" content="Let \(a_1, a_2, \ldots\) be an infinite set of non-negative samples taken from a distribution \(P_0(a)\), and write $$\tag{1}...">

    <meta name="author" content="Jonathan Landy">





<!-- Open Graph -->
<meta property="og:site_name" content="EFAVDB"/>
<meta property="og:title" content="Stochastic geometric series"/>
<meta property="og:description" content="Let \(a_1, a_2, \ldots\) be an infinite set of non-negative samples taken from a distribution \(P_0(a)\), and write $$\tag{1}..."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="./stochastic-geometric-series.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2015-09-13 06:00:00-07:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="./author/jonathan-landy.html">
<meta property="article:section" content="Finance, Statistics"/>
<meta property="og:image" content="./theme/images/post-bg.jpg">

<!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@efavdb">
    <meta name="twitter:title" content="Stochastic geometric series">
    <meta name="twitter:url" content="./stochastic-geometric-series.html">

        <meta name="twitter:image:src" content="./theme/images/post-bg.jpg">

      <meta name="twitter:description" content="Let \(a_1, a_2, \ldots\) be an infinite set of non-negative samples taken from a distribution \(P_0(a)\), and write $$\tag{1}...">

<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "name": "Stochastic geometric series",
  "headline": "Stochastic geometric series",
  "datePublished": "2015-09-13 06:00:00-07:00",
  "dateModified": "",
  "author": {
    "@type": "Person",
    "name": "Jonathan Landy",
    "url": "./author/jonathan-landy.html"
  },
  "image": "./theme/images/post-bg.jpg",
  "url": "./stochastic-geometric-series.html",
  "description": "Let \(a_1, a_2, \ldots\) be an infinite set of non-negative samples taken from a distribution \(P_0(a)\), and write $$\tag{1}..."
}
</script>
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>
          <li><a href="/" role="presentation">Home</a></li>
          <li><a href="/pages/about.html" role="presentation">About & Consulting</a></li>
          <li><a href="/archives.html" role="presentation">Archive</a></li>
          <li><a href="/tags.html" role="presentation">Tags</a></li>
          <li><a href="/pages/linselect.html" role="presentation">linselect - feature selection</a></li>


    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" >
      <div class="inner">
        <nav id="navigation">
            <span id="home-button" class="nav-button">
                <a class="home-button" href="./" title="Home"><i class="ic ic-arrow-left"></i> Home</a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">Stochastic geometric series</h1>
        <!-- TODO : Proper class for headline -->
        <span class="post-meta">
                <a href="./author/jonathan-landy.html">Jonathan Landy</a>
            | <time datetime="Sun 13 September 2015">Sun 13 September 2015</time>
        </span>
        <!-- TODO : Modified check -->
      </div>
    </header>

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
                <p>Let <span class="math">\(a_1, a_2, \ldots\)</span> be an infinite set of non-negative samples taken from a distribution <span class="math">\(P_0(a)\)</span>, and write<br>
</p>
<div class="math">$$\tag{1} \label{problem}  
S = 1 + a_1 + a_1 a_2 + a_1 a_2 a_3 + \ldots.  
$$</div>
<p><br>
Notice that if the <span class="math">\(a_i\)</span> were all the same, <span class="math">\(S\)</span> would be a regular geometric series, with value <span class="math">\(S = \frac{1}{1-a}\)</span>. How will the introduction of <span class="math">\(a_i\)</span> randomness change this sum? Will <span class="math">\(S\)</span> necessarily converge? How is <span class="math">\(S\)</span> distributed? In this post, we discuss some simple techniques to answer these questions.</p>
<p>Note: This post covers work done in collaboration with my aged p, S. Landy.</p>
<h3>Introduction -- a stock dividend problem</h3>
<p>To motivate the sum (\ref{problem}), consider the problem of evaluating the total output of a stock that pays dividends each year in proportion to its present value -- say <span class="math">\(x %\)</span>. The price dynamics of a typical stock can be reasonably modeled as a geometric random walk<span class="math">\(^1\)</span>:<br>
</p>
<div class="math">$$\label{prod} \tag{2}  
price(t) = price(t-1) * a_t,  
$$</div>
<p><br>
where <span class="math">\(a_t\)</span> is a random variable, having distribution <span class="math">\(P_0(a_t)\)</span>. Assuming this form for our hypothetical stock, its total lifetime dividends output will be<br>
</p>
<div class="math">$$\tag{3}  
x \times \sum_{t = 0}^{\infty} price(t) = x \times price(0) \left ( 1 + a_1 + a_1 a_2 + a_1 a_2 a_3 + \ldots \right)  
$$</div>
<p><br>
The inner term in parentheses here is precisely (\ref{problem}). More generally, a series of this form will be of interest pretty much whenever geometric series are: Population growth problems, the length of a cylindrical bacterium at a series of time steps<span class="math">\(^2\)</span>, etc. Will the nature of these sums change dramatically through the introduction of growth variance?</p>
<p>To characterize these types of stochastic geometric series, we will start below by considering their moments: This will allow us to determine the average value of (\ref{problem}), it's variance etc. This approach will also allow us to determine a condition that is both necessary and sufficient for the sum's convergence. Following this, we will introduce an integral equation satisfied by the <span class="math">\(P(S)\)</span> distribution. We demonstrate its application by solving the equation for a simple example.</p>
<h3>The moments of <span class="math">\(S\)</span></h3>
<p>To solve for the moments of <span class="math">\(S\)</span>, we use a trick similar to that used to sum the regular geometric series: We write<br>
</p>
<div class="math">$$\tag{4} \label{trick}  
S = 1 + a_1 + a_1 a_2 + \ldots \equiv 1 + a_1 T,  
$$</div>
<p><br>
where <span class="math">\(T = 1 + a_2 + a_2 a_3 + \ldots.\)</span> Now, because we assume that the <span class="math">\(a_i\)</span> are independent, it follows that <span class="math">\(a_1\)</span> and <span class="math">\(T\)</span> are independent. Further, <span class="math">\(S\)</span> and <span class="math">\(T\)</span> are clearly distributed identically, since they take the same form. Subtracting <span class="math">\(1\)</span> from both sides of the above equation, these observations imply<br>
</p>
<div class="math">$$\tag{5} \label{moments}  
\overline{(S-1)^k} = \sum_j {k \choose j} (-1)^j \overline{S^{k-j}} = \overline{ a^k S^k} = \overline{a^k} \ \overline{S^k}.  
$$</div>
<p><br>
This expression can be used to relate the moments of <span class="math">\(S\)</span> to those of <span class="math">\(a\)</span> -- a useful result, whenever the distribution of <span class="math">\(a\)</span> is known, allowing for the direct evaluation of its moments.</p>
<p>To illustrate, let us get the first couple of moments of <span class="math">\(S\)</span>, using (\ref{moments}). Setting <span class="math">\(k=1\)</span> above, we obtain<br>
</p>
<div class="math">$$\tag{6} \label{mean}  
\overline{S -1} = \overline{a} \overline{S} \ \ \to \ \ \overline{S} = \frac{1}{1 - \overline{a}}  
$$</div>
<p><br>
The right side here looks just like the usual geometric sum result, with <span class="math">\(a\)</span> replaced by its average value. Similarly, setting <span class="math">\(k =2\)</span> in (\ref{moments}), we can solve for the second moment of <span class="math">\(S\)</span>. Subtracting the square of the first gives the following expression for the sum's variance,<br>
</p>
<div class="math">$$\tag{7} \label{var}  
var(S) = \frac{var(a)}{(1 - \overline{a})^2(1 - \overline{a^2})}.  
$$</div>
<p><br>
As one might intuit, the variance of <span class="math">\(S\)</span> is proportional to the variance of <span class="math">\(a\)</span>.</p>
<p>Expressions (\ref{mean}) and (\ref{var}) are the most practical results of this post: They provide formal general expressions for the mean and variance for a sum of form (\ref{problem}). They can be used to provide a statistical estimate and error bar for a sum of form <span class="math">\(S\)</span> in any practical context. It is interesting/nice that the mean takes such a natural looking form -- one that many people likely make use of already, without putting much thought into.</p>
<p>The expressions above are also of some theoretical interest: Note, for example, that as <span class="math">\(\overline{a} \to 1\)</span> from below, the average value of <span class="math">\(S\)</span> diverges, and then becomes negative as <span class="math">\(a\)</span> goes above this value. This is clearly impossible, as <span class="math">\(S\)</span> is a sum of positive terms. This indicates that <span class="math">\(S\)</span> has no first moment whenever <span class="math">\(\overline{a} \geq 1\)</span>, while (\ref{mean}) holds whenever <span class="math">\(\overline{a} &lt; 1\)</span>. Similarly, (\ref{var}) indicates that the second moment of <span class="math">\(S\)</span> exists and is finite whenever <span class="math">\(\overline{a^2} &lt; 1\)</span>. In fact, this pattern continues for all <span class="math">\(k\)</span>: <span class="math">\(\overline{S^k}\)</span> exists and is finite if and only if <span class="math">\(\overline{a^k} &lt; 1\)</span> -- a result that can be obtained from (\ref{moments}). A rigorous and elementary proof of these statements can be found in an earlier work by Szabados and Szekeley<span class="math">\(^3\)</span>. The simple moment equation (\ref{moments}) can also be found there.</p>
<h3>Condition for the convergence of <span class="math">\(S\)</span></h3>
<p>A simple condition for the convergence of <span class="math">\(S\)</span> can also be obtained using (\ref{moments}). The trick is to consider the limit as <span class="math">\(k\)</span> goes to zero of the <span class="math">\(k\)</span>-th moments. This gives, for example, the average of <span class="math">\(1\)</span> with respect to <span class="math">\(P(S)\)</span>. If this is finite, then the distribution of <span class="math">\(P\)</span> is normalizable. Otherwise, <span class="math">\(S\)</span> must diverge: Setting <span class="math">\(k = \epsilon\)</span> in (\ref{moments}), expanding to first order in <span class="math">\(\epsilon\)</span> gives<br>
</p>
<div class="math">$$\tag{8} \label{approximate_log}  
\overline{ \exp [\epsilon \log (S -1) ]} \sim \overline{ 1 + \epsilon \log (S -1) } \sim \overline{ 1 + \epsilon \log S } \ \overline{ 1 + \epsilon \log a}.  
$$</div>
<p><br>
Solving for <span class="math">\(\overline{1}_S\)</span>, the average of <span class="math">\(1\)</span> with respect to <span class="math">\(P(S)\)</span>, gives<br>
</p>
<div class="math">$$\tag{9}  
\overline{1}_S = \frac{\overline{\log( 1 - \frac{1}{S})}}{\log a} + O(\epsilon).  
$$</div>
<p><br>
Like the integer moment expressions above, the right side here is finite up to the point where its denominator diverges. That is, the series will converge, if and only if <span class="math">\(\overline{\log a} &lt; 0\)</span>, a very simple condition<span class="math">\(^4\)</span>.</p>
<h3>Integral equation for the distribution <span class="math">\(P(S)\)</span></h3>
<p>We have also found that one can sometimes go beyond solving for the moments of <span class="math">\(S\)</span>, and instead solve directly for its full distribution: Integrating (\ref{trick}) over <span class="math">\(a\)</span> gives<br>
</p>
<div class="math">$$\tag{10} \label{int}  
P(S_0) = \int da P_0(a) \int dS P(S) \delta(1+ a S - S_0) = \int \frac{da}{a} P_0(a) P \left (\frac{S_0 -1}{a} \right).  
$$</div>
<p><br>
This is a general, linear integral equation for <span class="math">\(P(S)\)</span>. At least in some cases, it can solved in closed-form. An example follows.</p>
<p><strong>Uniformly distributed <span class="math">\(a_i\)</span></strong></p>
<p>To demonstrate how one might solve the equation (\ref{int}), we consider here the case where the <span class="math">\(a_i\)</span> are uniform on <span class="math">\([0,1]\)</span>. In this case, writing <span class="math">\(a = \frac{S_0 -1}{v}\)</span>, (\ref{int}) goes to<br>
</p>
<div class="math">$$\tag{11} \label{int2}  
P(S_0) = \int_{S_0-1}^{\infty} P\left (v\right) \frac{1}{v}dv.  
$$</div>
<p><br>
To progress, we differentiate with respect to <span class="math">\(S_0\)</span>, which gives<br>
</p>
<div class="math">$$\tag{12} \label{delay}  
P^{\prime} (S_0)\equiv - \frac{1 }{S_0 -1}\times P\left (S_0 -1\right).  
$$</div>
<p><br>
Equation (\ref{delay}) is a <a href="https://en.wikipedia.org/wiki/Delay_differential_equation">delay differential equation</a>. It can be solved through iterated integrations: To initiate the process, we note that <span class="math">\(P(S_0)\)</span> is equal to zero for all <span class="math">\(S_0&lt; 1\)</span>. Plugging this observation into (\ref{delay}) implies that <span class="math">\(P(S_0) \equiv J\)</span> -- some constant -- for <span class="math">\(S \in (1,2)\)</span>. Continuing in this fashion, repeated integrations of (\ref{delay}) gives<br>
</p>
<div class="math">$$\tag{13}  
P (S_0) = \begin{cases}  
J, \ \ \ S_0 \in (1,2) \  
J[1 - \log (S_0 -1)], \ \ \ S_0 \in (2,3) \  
J \left [ 1 - \log(S_0 - 1) + Li_2(2-S_0) + \frac{ \log(S_0 - 2)}{\log(S_0 - 1)} - Li_2(-1) \right ], \ \ S_0 \in (3,4) \  
\ldots,  
\end{cases}  
$$</div>
<p><br>
where <span class="math">\(Li_2\)</span> is the polylogarithm function.  </p>
<p>In practice, to find <span class="math">\(J\)</span> one can solve (\ref{delay}) numerically, requiring <span class="math">\(P(S)\)</span> to be normalized. The figure below compares the result to a simulation estimate, obtained via binning the results of 250,000 random sums of form (\ref{problem}). The two agree nicely.</p>
<p><a href="./wp-content/uploads/2015/08/Screen-Shot-2015-08-16-at-10.34.46-PM.png"><img alt="Screen Shot 2015-08-16 at 10.34.46 PM" src="./wp-content/uploads/2015/08/Screen-Shot-2015-08-16-at-10.34.46-PM.png"></a></p>
<h3>Discussion</h3>
<p>Consideration of this problem was motivated by a geometric series of type (\ref{problem}) that arose in my work at Square. In this case, I was interested in understanding the bias and variance in the natural estimate (\ref{mean}) to this problem. After some weeks of tinkering with S Landy, I was delighted to find that rigorous, simple results could be obtained to characterize these sums, the simplest being the moment and convergence results above. We now realize that these particular issues have already been well- (and better-)studied, by others<span class="math">\(^3\)</span>.</p>
<p>As for the integral equation approach, we have not found any other works aimed at solving this problem in general. The method discussed in the example above can be used for any <span class="math">\(P_0(a)\)</span> that is uniform over a finite segment. We have also found solutions for a few other cases. Unfortunately, we have so far been unable to obtain a formal, general solution in closed form. However, we note that standard iterative approaches can always be used to estimate the solution to (\ref{int}). Finally, in cases where all moments exist, these can also be used to determine <span class="math">\(P\)</span>.</p>
<h4>References and comments</h4>
<p>[1] For a discussion on the geometric random walk model for stocks, see <a href="http://people.duke.edu/~rnau/411georw.htm">here</a>.</p>
<p>[2] Elongated bacteria -- eg., e. coli -- grow longer at an exponential rate -- see my <a href="https://www.sites.google.com/site/Jonathan Landy/%282014%29cellgrowth.pdf?attredirects=0&amp;d=1">paper on how cell shape affects growth rates</a>. Due to randomness inherent in the growth rates, bacteria populations will have a length distribution, similar in form to <span class="math">\(P(S)\)</span>.</p>
<p>[3] "An exponential functional of random walks" by Szabados and Szekeley, Journal of Applied Probability 2003.</p>
<p>[4] Although we have given only a hand-waving argument for this result, the authors of [3] state -- and give a reference for -- the fact that it can be proven using the law of large numbers: By independence of the <span class="math">\(a_i\)</span>, the <span class="math">\(k\)</span>-th term in the series approaches <span class="math">\((\overline{\log a})^k\)</span> with probability one, at large <span class="math">\(k\)</span>. Simple convergence criteria then give the result.</p>
<p>[5] The moment equation (\ref{moments}) can also be obtained from the integral equation (\ref{int}), where it arrises from the application of the convolution theorem.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            </section>

            <section class="post-info">
                <div class="post-share">
                    <a class="twitter" href="https://twitter.com/share?text=Stochastic geometric series&amp;url=./stochastic-geometric-series.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <i class="ic ic-twitter"></i><span class="hidden">Twitter</span>
                    </a>
                    <a class="facebook" href="https://www.facebook.com/sharer/sharer.php?u=./stochastic-geometric-series.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <i class="ic ic-facebook"></i><span class="hidden">Facebook</span>
                    </a>
                    <a class="googleplus" href="https://plus.google.com/share?url=./stochastic-geometric-series.html" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <i class="ic ic-googleplus"></i><span class="hidden">Google+</span>
                    </a>
                    <div class="clear"></div>
                </div>


                <div class="clear"></div>

                <aside class="post-author">


                        <figure class="post-author-avatar">
                            <img src=".//wp-content/uploads/2014/12/JonathanLinkedIn.jpg" alt="Jonathan Landy" />
                        </figure>
                    <div class="post-author-bio">
                        <h4 class="post-author-name"><a href="./author/jonathan-landy.html">Jonathan Landy</a></h4>
                            <p class="post-author-about">Jonathan grew up in the midwest and then went to school at Caltech and UCLA. Following this, he did two postdocs, one at UCSB and one at UC Berkeley.  His academic research focused primarily on applications of statistical mechanics, but his professional passion has always been in the mastering, development, and practical application of slick math methods/tools. He worked as a data-scientist at Square for four years and is now working on a quantitative investing startup.</p>
                        <!-- Social linkes in alphabet order. -->
                    </div>
                    <div class="clear"></div>
                </aside>

                </section>


                <aside class="post-nav">
                    <a class="post-nav-next" href="./pandas-tips-and-tricks.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-left"></i>
                                <h2 class="post-nav-title">Getting started with Pandas</h2>
                            <p class="post-nav-excerpt">We have made use of Python's Pandas package in a variety of posts on the site. These...</p>
                        </section>
                    </a>
                    <a class="post-nav-prev" href="./build-a-web-scraper-lit-search.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-right"></i>
                                <h2 class="post-nav-title">Build a web scraper for a literature search - from soup to nuts</h2>
                            <p class="post-nav-excerpt">Code, references, and examples of this project are on Github. In this post, I'll...</p>
                        </section>
                    </a>
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>

    <footer id="footer">
      <div class="inner">
        <section class="credits">
        </section>
      </div>
    </footer>
  </section>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script type="text/javascript" src="./theme/js/script.js"></script>

</body>
</html>