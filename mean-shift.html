<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>The mean shift clustering algorithm</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
<link href="./mean-shift.html" rel="canonical" />
  <!-- Feed -->

  <link href="./theme/css/style.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="./theme/css/code_blocks/github.css" rel="stylesheet">


  <!-- Custom fonts -->
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->



    <meta name="description" content="Mean shift clustering Mean shift clustering is a general non-parametric cluster finding procedure -- introduced by Fukunaga and...">

    <meta name="author" content="Damien RJ">





<!-- Open Graph -->
<meta property="og:site_name" content="EFAVDB"/>
<meta property="og:title" content="The mean shift clustering algorithm"/>
<meta property="og:description" content="Mean shift clustering Mean shift clustering is a general non-parametric cluster finding procedure -- introduced by Fukunaga and..."/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="./mean-shift.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2015-04-21 09:17:00-07:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="./author/damien-rj.html">
<meta property="article:section" content="Methods, Theory"/>
<meta property="og:image" content="./theme/images/post-bg.jpg">

<!-- Twitter Card -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@efavdb">
    <meta name="twitter:title" content="The mean shift clustering algorithm">
    <meta name="twitter:url" content="./mean-shift.html">

        <meta name="twitter:image:src" content="./theme/images/post-bg.jpg">

      <meta name="twitter:description" content="Mean shift clustering Mean shift clustering is a general non-parametric cluster finding procedure -- introduced by Fukunaga and...">

<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "name": "The mean shift clustering algorithm",
  "headline": "The mean shift clustering algorithm",
  "datePublished": "2015-04-21 09:17:00-07:00",
  "dateModified": "",
  "author": {
    "@type": "Person",
    "name": "Damien RJ",
    "url": "./author/damien-rj.html"
  },
  "image": "./theme/images/post-bg.jpg",
  "url": "./mean-shift.html",
  "description": "Mean shift clustering Mean shift clustering is a general non-parametric cluster finding procedure -- introduced by Fukunaga and..."
}
</script>
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>
          <li><a href="/" role="presentation">Home</a></li>
          <li><a href="/pages/about.html" role="presentation">About & Consulting</a></li>
          <li><a href="/archives.html" role="presentation">Archive</a></li>
          <li><a href="/tags.html" role="presentation">Tags</a></li>
          <li><a href="/pages/linselect.html" role="presentation">linselect - feature selection</a></li>


    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" >
      <div class="inner">
        <nav id="navigation">
            <span id="home-button" class="nav-button">
                <a class="home-button" href="./" title="Home"><i class="ic ic-arrow-left"></i> Home</a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">The mean shift clustering algorithm</h1>
        <!-- TODO : Proper class for headline -->
        <span class="post-meta">
                <a href="./author/damien-rj.html">Damien Ramunno-Johnson</a>
            | <time datetime="Tue 21 April 2015">Tue 21 April 2015</time>
        </span>
        <!-- TODO : Modified check -->
      </div>
    </header>

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
                <h3>Mean shift clustering</h3>
<p>Mean shift clustering is a general non-parametric cluster finding procedure -- introduced by Fukunaga and Hostetler [<a href="#1">1</a>], and popular within the computer vision field. Nicely, and in contrast to the more-well-known K-means clustering algorithm, the output of mean shift does not depend on any explicit assumptions on the shape of the point distribution, the number of clusters, or any form of random initialization.  </p>
<p>We describe the mean shift algorithm in some detail in the <a href="#Tech">technical background section</a> at the end of this post. However, its essence is readily explained in a few words: Essentially, mean shift treats the clustering problem by supposing that all points given represent samples from some underlying probability density function, with regions of high sample density corresponding to the local maxima of this distribution. To find these local maxima, the algorithm works by allowing the points to attract each other, via what might be considered a short-ranged ``gravitational" force. Allowing the points to gravitate towards areas of higher density, one can show that they will eventually coalesce at a series of points, close to the local maxima of the distribution. Those data points that converge to the same local maxima are considered to be members of the same cluster.</p>
<p>In the next couple of sections, we illustrate application of the algorithm to a couple of problems. We make use of the python package <a href="http://scikit-learn.org/stable/">SkLearn</a>, which contains a mean shift implementation. Following this, we provide a quick discussion and an appendix on technical details.</p>
<h3>Mean shift clustering in action</h3>
<p>In today's post we will have two examples. First, we will show how to use mean shift clustering to identify clusters of data in a 2D data set. Second, we will use the algorithm to segment a picture based on the colors in the image. To do this we need a handful of libraries from sklearn, numpy, matplotlib, and the Python Imaging Library (PIL) to handle reading in a jpeg image.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>  
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">MeanShift</span><span class="p">,</span> <span class="n">estimate_bandwidth</span>  
<span class="kn">from</span> <span class="nn">sklearn.datasets.samples_generator</span> <span class="kn">import</span> <span class="n">make_blobs</span>  
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>  
<span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">cycle</span>  
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>  
</pre></div>


<h4>Finding clusters in a 2D data set</h4>
<p>This first example is based off of the sklearn <a href="http://scikit-learn.org/stable/auto_examples/cluster/plot_mean_shift.html">tutorial</a> for mean shift clustering: We generate data points centered at 4 locations, making use of sklearn's make_blobs library. To apply the clustering algorithm to the points generated, we must first set the attractive interaction length between examples, also know as the algorithm's bandwidth. Sklearn's implementation contains a built-in function that allows it to automatically estimate a reasonable value for this, based upon the typical distance between examples. We make use of that below, carry out the clustering, and then plot the results.</p>
<div class="highlight"><pre><span></span><span class="err">#</span><span class="o">%%</span><span class="w"> </span><span class="n">Generate</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="k">data</span><span class="w">  </span>
<span class="n">centers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">[1, 1</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">-.75, -1</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">1, -1</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">-3, 2</span><span class="o">]</span><span class="err">]</span><span class="w">  </span>
<span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span><span class="w"> </span><span class="n">centers</span><span class="o">=</span><span class="n">centers</span><span class="p">,</span><span class="w"> </span><span class="n">cluster_std</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span><span class="w"></span>

<span class="err">#</span><span class="o">%%</span><span class="w"> </span><span class="k">Compute</span><span class="w"> </span><span class="n">clustering</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">MeanShift</span><span class="w"></span>

<span class="err">#</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="n">bandwidth</span><span class="w"> </span><span class="n">can</span><span class="w"> </span><span class="n">be</span><span class="w"> </span><span class="n">automatically</span><span class="w"> </span><span class="n">estimated</span><span class="w">  </span>
<span class="n">bandwidth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">estimate_bandwidth</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">quantile</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span><span class="w">  </span>
<span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span><span class="w">  </span>
<span class="n">ms</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">MeanShift</span><span class="p">(</span><span class="n">bandwidth</span><span class="o">=</span><span class="n">bandwidth</span><span class="p">,</span><span class="w"> </span><span class="n">bin_seeding</span><span class="o">=</span><span class="k">True</span><span class="p">)</span><span class="w">  </span>
<span class="n">ms</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="w">  </span>
<span class="n">labels</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ms</span><span class="p">.</span><span class="n">labels_</span><span class="w">  </span>
<span class="n">cluster_centers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ms</span><span class="p">.</span><span class="n">cluster_centers_</span><span class="w"></span>

<span class="n">n_clusters_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labels</span><span class="p">.</span><span class="nf">max</span><span class="p">()</span><span class="o">+</span><span class="mi">1</span><span class="w"></span>

<span class="err">#</span><span class="o">%%</span><span class="w"> </span><span class="n">Plot</span><span class="w"> </span><span class="k">result</span><span class="w">  </span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="w">  </span>
<span class="n">plt</span><span class="p">.</span><span class="n">clf</span><span class="p">()</span><span class="w"></span>

<span class="n">colors</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">cycle</span><span class="p">(</span><span class="s1">&#39;bgrcmykbgrcmykbgrcmykbgrcmyk&#39;</span><span class="p">)</span><span class="w">  </span>
<span class="k">for</span><span class="w"> </span><span class="n">k</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">zip</span><span class="p">(</span><span class="k">range</span><span class="p">(</span><span class="n">n_clusters_</span><span class="p">),</span><span class="w"> </span><span class="n">colors</span><span class="p">)</span><span class="err">:</span><span class="w">  </span>
<span class="n">my_members</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">labels</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">k</span><span class="w">  </span>
<span class="n">cluster_center</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">cluster_centers</span><span class="o">[</span><span class="n">k</span><span class="o">]</span><span class="w">  </span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="o">[</span><span class="n">my_members, 0</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">X</span><span class="o">[</span><span class="n">my_members, 1</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">col</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s1">&#39;.&#39;</span><span class="p">)</span><span class="w">  </span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cluster_center</span><span class="o">[</span><span class="n">0</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">cluster_center</span><span class="o">[</span><span class="n">1</span><span class="o">]</span><span class="p">,</span><span class="w">  </span>
<span class="s1">&#39;o&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">markerfacecolor</span><span class="o">=</span><span class="n">col</span><span class="p">,</span><span class="w">  </span>
<span class="n">markeredgecolor</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span><span class="w"> </span><span class="n">markersize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span><span class="w">  </span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Estimated number of clusters: %d&#39;</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">n_clusters_</span><span class="p">)</span><span class="w">  </span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span><span class="w">  </span>
</pre></div>


<p>As you can see below, the algorithm has found clusters centered on each of the blobs we generated.</p>
<p><a href="./wp-content/uploads/2015/03/plot1.png"><img alt="Plot 1" src="./wp-content/uploads/2015/03/plot1.png"></a></p>
<h4>Segmenting a color photo</h4>
<p>In the first example, we were using mean shift clustering to look for spatial clusters. In our second example, we will instead explore 3D color space, RGB, by considering pixel values taken from an image of a toy car. The procedure is similar -- here, we cluster points in 3d, but instead of having data(x,y) we have data(r,g,b) taken from the image's RGB pixel values. Clustering these color values in this 3d space returns a series of clusters, where the pixels in those clusters are similar in RGB space. Recoloring pixels according to their cluster, we obtain a segmentation of the original image.</p>
<div class="highlight"><pre><span></span><span class="o">#%%</span> <span class="n">Part</span> <span class="mi">2</span><span class="p">:</span> <span class="n">Color</span> <span class="n">image</span> <span class="n">segmentation</span> <span class="k">using</span> <span class="n">mean</span> <span class="n">shift</span>

<span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="p">.</span><span class="k">open</span><span class="p">(</span><span class="s1">&#39;toy.jpg&#39;</span><span class="p">)</span>  
<span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">array</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

<span class="o">#</span><span class="n">Need</span> <span class="k">to</span> <span class="k">convert</span> <span class="n">image</span> <span class="k">into</span> <span class="n">feature</span> <span class="nb">array</span> <span class="n">based</span>  
<span class="o">#</span><span class="k">on</span> <span class="n">rgb</span> <span class="n">intensities</span>  
<span class="n">flat_image</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

<span class="o">#</span><span class="n">Estimate</span> <span class="n">bandwidth</span>  
<span class="n">bandwidth2</span> <span class="o">=</span> <span class="n">estimate_bandwidth</span><span class="p">(</span><span class="n">flat_image</span><span class="p">,</span>  
<span class="n">quantile</span><span class="o">=</span><span class="p">.</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>  
<span class="n">ms</span> <span class="o">=</span> <span class="n">MeanShift</span><span class="p">(</span><span class="n">bandwidth2</span><span class="p">,</span> <span class="n">bin_seeding</span><span class="o">=</span><span class="k">True</span><span class="p">)</span>  
<span class="n">ms</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">flat_image</span><span class="p">)</span>  
<span class="n">labels</span><span class="o">=</span><span class="n">ms</span><span class="p">.</span><span class="n">labels_</span>

<span class="o">#</span> <span class="n">Plot</span> <span class="n">image</span> <span class="n">vs</span> <span class="n">segmented</span> <span class="n">image</span>  
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>  
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>  
<span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  
<span class="n">plt</span><span class="p">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="p">[</span><span class="mi">851</span><span class="p">,</span><span class="mi">1280</span><span class="p">]))</span>  
<span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</pre></div>


<p>The bottom image below illustrates that one can effectively use this approach to identify the key shapes within an image, all without doing any image processing to get rid of glare or background -- pretty great!<br>
<a href="./wp-content/uploads/2015/03/test-e1428358370930.png"><img alt="" src="./wp-content/uploads/2015/03/test-e1428358370930.png"></a></p>
<h3>Discussion</h3>
<p>Although mean shift is a reasonably versatile algorithm, it has primarily been applied to problems in computer vision, where it has been used for image segmentation, clustering, and video tracking. Application to big data problems can be challenging due to the fact the algorithm can become relatively slow in this limit. However, research is presently underway to speed up its convergence, which should enable its application to larger data sets.</p>
<p>Mean shift pros:</p>
<ol>
<li>No assumptions on the shape or number of data clusters.</li>
<li>The procedure only has one parameter, the bandwidth.</li>
<li>Output doesn't depend on initializations.</li>
</ol>
<p>Mean shift cons:</p>
<ol>
<li>Output does depend on bandwidth: too small and convergence is slow, too large and some clusters may be missed.</li>
<li>Computationally expensive for large feature spaces.</li>
<li>Often slower than K-Means clustering</li>
</ol>
<p>Technical details follow.</p>
<h3 id="Tech">Technical background</h3>
<h4>Kernel density estimation</h4>
<p>A general formulation of the mean shift algorithm can be developed through consideration of density kernels. These effectively work by smearing out each point example in space over some small window. Summing up the mass from each of these smeared units gives an estimate for the probability density at every point in space (by smearing, we are able to obtain estimates at locations that do not sit exactly atop any example). This approach is often referred to as <a href="http://en.wikipedia.org/wiki/Kernel_density_estimation">kernel density estimation</a> -- a method for density estimation that often converges more quickly than binning, or histogramming, and one that also nicely returns a continuous estimate for the density function.</p>
<p>To illustrate, suppose we are given a data set <span class="math">\(\{\textbf{u}_i\}\)</span> of points in d-dimensional space, sampled from some larger population, and that we have chosen a kernel <span class="math">\(K\)</span> having bandwidth parameter <span class="math">\(h\)</span>. Together, these data and kernel function return the following kernel density estimator for the full population's density function<br>
</p>
<div class="math">\begin{eqnarray}  
f_K(\textbf{u}) = \frac{1}{nh^d}\sum\limits_{i=1}^n K(\frac{\textbf{u}-\textbf{u}_i}{h})  
\end{eqnarray}</div>
<p><br>
The kernel (smearing) function here is required to satisfy the following two conditions:</p>
<ol>
<li><span class="math">\(\int K(\textbf{u})d\textbf{u} = 1\)</span></li>
<li><span class="math">\(K(\textbf{u})=K(\vert \textbf{u} \vert)\)</span> for all values of <span class="math">\(\textbf{u}\)</span></li>
</ol>
<p>The first requirement is needed to ensure that our estimate is normalized, and the second is associated with the symmetry of our space. Two popular kernel functions that satisfy these conditions are given by</p>
<ol>
<li>Flat/Uniform <span class="math">\(<div class="math">\begin{align}  
    K(\textbf{u}) = \frac{1}{2}\left\{  
    \begin{array}{lr}  
    1 &amp; -1 \le \vert \textbf{u} \vert \le 1\  
    0 &amp; else  
    \end{array}  
    \right.  
    \end{align}</div>\)</span></li>
<li>Gaussian = <span class="math">\(K(\textbf{u}) = \frac{1}{\left(2\pi\right)^{d/2}} e^{-\frac{1}{2} \vert \textbf{u} \vert^2}\)</span></li>
</ol>
<p>Below we plot an example in 1-d using the gaussian kernel to estimate the density of some population along the x-axis. You can see that each sample point adds a small Gaussian to our estimate, centered about it: The equations above may look a bit intimidating, but the graphic here should clarify that the concept is pretty straightforward.</p>
<p>[caption id="attachment_1563" align="aligncenter" width="765"]<img alt="KDE plot" src="http://efavdb.com/wp-content/uploads/2015/03/KDE-plot-1024x675.png"> Example of a kernel density estimation using a gaussian kernel for each data point: Adding up small Gaussians about each example returns our net estimate for the total density, the black curve.[/caption]</p>
<h4>Mean shift algorithm</h4>
<p>Recall that the basic goal of the mean shift algorithm is to move particles in the direction of local increasing density. To obtain an estimate for this direction, a gradient is applied to the kernel density estimate discussed above. Assuming an angularly symmetric kernel function, <span class="math">\(K(\textbf{u}) = K(\vert \textbf{u} \vert)\)</span>, one can show that this gradient takes the form<br>
</p>
<div class="math">\begin{eqnarray}  
\nabla f_K(\textbf{u}) = \frac{2}{nh^{d+2}} \left ( \sum\limits_{i=1}^n g(\left \vert \frac{\textbf{u}-\textbf{u}_i}{h} \right \vert) \right ) \textbf{m}(\textbf{u}).  
\end{eqnarray}</div>
<p><br>
where<br>
</p>
<div class="math">\begin{eqnarray} \textbf{m}(\textbf{u}) = \left ( \frac{\sum\limits_{i=1}^n \textbf{u}_i g(\left \vert \frac{\textbf{u}-\textbf{u}_i}{h} \right \vert)}{\sum\limits_{i=1}^n g(\left \vert \frac{\textbf{u}-\textbf{u}_i}{h} \right \vert)}-\textbf{u} \right ),  
\end{eqnarray}</div>
<p><br>
and <span class="math">\(g(\vert \textbf{u} \vert ) = -K'(\vert \textbf{u} \vert)\)</span> is the derivative of the selected kernel profile. The vector <span class="math">\(\textbf{m}(\textbf{u})\)</span> here, called the mean shift vector, points in the direction of increasing density -- the direction we must move our example. With this estimate, then, the mean shift algorithm protocol becomes</p>
<ul>
<li>Compute the mean shift vector <span class="math">\(\textbf{m}(\textbf{u}_i)\)</span>, evaluated at the location of each training example <span class="math">\(\textbf{u}_i\)</span></li>
<li>Move each example from <span class="math">\(\textbf{u}_i \to \textbf{u}_i + \textbf{m}(\textbf{u}_i)\)</span></li>
<li>Repeat until convergence -- ie, until the particles have reached equilibrium.</li>
</ul>
<p>As a final step, one determines which examples have ended up at the same points, marking them as members of the same cluster.</p>
<p>For a proof of convergence and further mathematical details, see <a href="https://courses.csail.mit.edu/6.869/handouts/PAMIMeanshift.pdf">Comaniciu &amp; Meer (2002)</a> [<a href="#2">2</a>].</p>
<p>​1. Fukunaga and Hostetler, "The Estimation of the Gradient of a Density Function, with Applications in Pattern Recognition", IEEE Transactions on Information Theory vol 21 , pp 32-40 ,1975<br>
2. Dorin Comaniciu and Peter Meer, Mean Shift : A Robust approach towards feature space analysis, IEEE Transactions on Pattern Analysis and Machine Intelligence vol 24 No 5 May 2002.</p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
            </section>

            <section class="post-info">
                <div class="post-share">
                    <a class="twitter" href="https://twitter.com/share?text=The mean shift clustering algorithm&amp;url=./mean-shift.html" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <i class="ic ic-twitter"></i><span class="hidden">Twitter</span>
                    </a>
                    <a class="facebook" href="https://www.facebook.com/sharer/sharer.php?u=./mean-shift.html" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <i class="ic ic-facebook"></i><span class="hidden">Facebook</span>
                    </a>
                    <a class="googleplus" href="https://plus.google.com/share?url=./mean-shift.html" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <i class="ic ic-googleplus"></i><span class="hidden">Google+</span>
                    </a>
                    <div class="clear"></div>
                </div>


                <div class="clear"></div>

                <aside class="post-author">


                        <figure class="post-author-avatar">
                            <img src=".//wp-content/uploads/2014/12/headshot.jpg" alt="Damien Ramunno-Johnson" />
                        </figure>
                    <div class="post-author-bio">
                        <h4 class="post-author-name"><a href="./author/damien-rj.html">Damien Ramunno-Johnson</a></h4>
                            <p class="post-author-about">Damien is a highly experienced researcher with a background in clinical and applied research. Like JSL, he got his PhD at UCLA. He has many years of experience working with imaging, and has a particularly strong background in image segmentation, registration, detection, data analysis, and more recently machine learning. He now works as a data-scientist at Square in San Francisco.</p>
                        <!-- Social linkes in alphabet order. -->
                    </div>
                    <div class="clear"></div>
                </aside>

                </section>


                <aside class="post-nav">
                    <a class="post-nav-next" href="./mlb-week-2-review-week-3-predictions.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-left"></i>
                                <h2 class="post-nav-title">MLB week 2 review, week 3 predictions</h2>
                            <p class="post-nav-excerpt">This week, we went 52/95, giving 54.7% accuracy, a value comparable to the previous...</p>
                        </section>
                    </a>
                    <a class="post-nav-prev" href="./nba-week-22-results-nba-season-review-mlb-week-1.html">
                        <section class="post-nav-teaser">
                            <i class="ic ic-arrow-right"></i>
                                <h2 class="post-nav-title">NBA week 22 results, NBA season review, MLB week 1</h2>
                            <p class="post-nav-excerpt">We finished the NBA regular season strong, with correct guesses on 41 of 56 games this...</p>
                        </section>
                    </a>
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>

    <footer id="footer">
      <div class="inner">
        <section class="credits">
        </section>
      </div>
    </footer>
  </section>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script type="text/javascript" src="./theme/js/script.js"></script>

</body>
</html>